{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nawidayima/IPHR_Direction/blob/main/notebooks/08_sycophancy_probes.ipynb)\n",
    "\n",
    "# Train Sycophancy Detection Probes\n",
    "\n",
    "**Goal:** Find a direction in activation space that separates \"sycophantic\" from \"maintained\" behavior.\n",
    "\n",
    "**Project Plan Reference:** PIVOT Phase, Hours 13-15\n",
    "\n",
    "**Key methods:**\n",
    "1. **Difference-in-Means (DiM):** Simple baseline - find the direction between class centroids\n",
    "2. **Logistic Regression:** Learn the optimal separating direction with regularization\n",
    "\n",
    "**Success criteria:**\n",
    "- ROC-AUC > 0.7 = weak signal (proceed to steering)\n",
    "- ROC-AUC ~ 0.5 = no signal (informative negative result)\n",
    "\n",
    "**Setup:** Run Cell 0 once to install dependencies, then restart runtime and run from Cell 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 0: Setup - Clone repo and install dependencies\n",
    "# NOTE: After running this cell, RESTART RUNTIME (Runtime > Restart runtime)\n",
    "#       Then skip this cell and run from Cell 1 onwards\n",
    "\n",
    "import os\n",
    "\n",
    "# Clone repo (only if not already cloned)\n",
    "if not os.path.exists('/content/IPHR_Direction'):\n",
    "    !git clone https://github.com/nawidayima/IPHR_Direction.git\n",
    "    %cd /content/IPHR_Direction\n",
    "else:\n",
    "    %cd /content/IPHR_Direction\n",
    "    !git pull  # Get latest changes\n",
    "\n",
    "# Install dependencies\n",
    "!pip install torch numpy pandas scikit-learn matplotlib -q\n",
    "\n",
    "# Install package in editable mode\n",
    "!pip install -e . -q\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Setup complete! Restart runtime and run from Cell 1.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Scikit-learn for ML\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Imports complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Device check\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# For this notebook, we mainly use CPU since probe training is fast\n",
    "# The heavy lifting (activation extraction) was done in notebook 07"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Load Activations\n",
    "\n",
    "We load the pre-extracted activations from notebook 07. The data structure is:\n",
    "\n",
    "```python\n",
    "{\n",
    "    'activations': {layer_idx: Tensor[n_samples, d_model]},\n",
    "    'labels': Tensor[n_samples],  # 1=sycophantic, 0=maintained\n",
    "    'metadata': [{'question_id', 'category', 'label'}, ...]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Load activations\n",
    "%cd /content/IPHR_Direction\n",
    "\n",
    "# Find most recent sycophancy run\n",
    "RUN_DIR = Path(\"experiments\")\n",
    "sycophancy_runs = sorted(RUN_DIR.glob(\"run_*_sycophancy\"), reverse=True)\n",
    "\n",
    "if sycophancy_runs:\n",
    "    RUN_DIR = sycophancy_runs[0]\n",
    "    print(f\"Using: {RUN_DIR}\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"No sycophancy runs found.\")\n",
    "\n",
    "# Token position from notebook 07\n",
    "TOKEN_POSITION = \"first_generated\"\n",
    "\n",
    "ACTIVATIONS_PATH = RUN_DIR / f\"activations/sycophancy_activations_{TOKEN_POSITION}.pt\"\n",
    "\n",
    "if not ACTIVATIONS_PATH.exists():\n",
    "    # Try without position suffix (legacy)\n",
    "    ACTIVATIONS_PATH = RUN_DIR / \"activations/sycophancy_activations.pt\"\n",
    "\n",
    "data = torch.load(ACTIVATIONS_PATH)\n",
    "\n",
    "print(f\"\\nLoaded activation data:\")\n",
    "print(f\"  Model: {data['model_name']}\")\n",
    "print(f\"  Token position: {data.get('token_position', 'unknown')}\")\n",
    "print(f\"  Layers: {data['layers']}\")\n",
    "print(f\"  d_model: {data['d_model']}\")\n",
    "print(f\"  n_samples: {data['n_samples']}\")\n",
    "print(f\"\\nActivation shapes:\")\n",
    "for layer, acts in data['activations'].items():\n",
    "    print(f\"  Layer {layer}: {acts.shape}\")\n",
    "print(f\"\\nLabels: {data['labels'].shape}\")\n",
    "print(f\"  Sycophantic (1): {data['labels'].sum().item()}\")\n",
    "print(f\"  Maintained (0): {(~data['labels'].bool()).sum().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Display label distribution by category\n",
    "metadata = data['metadata']\n",
    "labels = data['labels'].numpy()\n",
    "\n",
    "# Count by category and label\n",
    "category_counts = {}\n",
    "for m, label in zip(metadata, labels):\n",
    "    category = m['category']\n",
    "    if category not in category_counts:\n",
    "        category_counts[category] = {'sycophantic': 0, 'maintained': 0}\n",
    "    if label == 1:\n",
    "        category_counts[category]['sycophantic'] += 1\n",
    "    else:\n",
    "        category_counts[category]['maintained'] += 1\n",
    "\n",
    "print(\"Distribution by category:\")\n",
    "print(\"-\" * 50)\n",
    "for category, counts in sorted(category_counts.items()):\n",
    "    total = counts['sycophantic'] + counts['maintained']\n",
    "    syc_rate = counts['sycophantic'] / total if total > 0 else 0\n",
    "    print(f\"{category:12s}: {counts['sycophantic']:3d} sycophantic, {counts['maintained']:3d} maintained (rate: {syc_rate:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Train/Test Split\n",
    "\n",
    "We split by `question_id` to avoid data leakage. This ensures that the same question doesn't appear in both train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Train/test split by question_id\n",
    "\n",
    "# Extract question_ids\n",
    "question_ids = np.array([m['question_id'] for m in metadata])\n",
    "unique_questions = np.unique(question_ids)\n",
    "\n",
    "print(f\"Total samples: {len(labels)}\")\n",
    "print(f\"Unique questions: {len(unique_questions)}\")\n",
    "\n",
    "# Create mapping from question to samples\n",
    "question_to_indices = {}\n",
    "question_to_label = {}\n",
    "\n",
    "for i, (qid, label) in enumerate(zip(question_ids, labels)):\n",
    "    if qid not in question_to_indices:\n",
    "        question_to_indices[qid] = []\n",
    "        question_to_label[qid] = label\n",
    "    question_to_indices[qid].append(i)\n",
    "\n",
    "# Use GroupShuffleSplit to split by question\n",
    "question_labels = np.array([question_to_label[qid] for qid in unique_questions])\n",
    "\n",
    "splitter = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_q_idx, test_q_idx = next(splitter.split(unique_questions, question_labels, groups=unique_questions))\n",
    "\n",
    "train_questions = set(unique_questions[train_q_idx])\n",
    "test_questions = set(unique_questions[test_q_idx])\n",
    "\n",
    "# Map back to sample indices\n",
    "train_indices = []\n",
    "test_indices = []\n",
    "\n",
    "for qid in unique_questions:\n",
    "    if qid in train_questions:\n",
    "        train_indices.extend(question_to_indices[qid])\n",
    "    else:\n",
    "        test_indices.extend(question_to_indices[qid])\n",
    "\n",
    "train_indices = np.array(train_indices)\n",
    "test_indices = np.array(test_indices)\n",
    "\n",
    "print(f\"\\nSplit results:\")\n",
    "print(f\"  Train questions: {len(train_questions)} -> {len(train_indices)} samples\")\n",
    "print(f\"  Test questions: {len(test_questions)} -> {len(test_indices)} samples\")\n",
    "print(f\"\\nTrain label distribution:\")\n",
    "print(f\"  Sycophantic: {labels[train_indices].sum()}\")\n",
    "print(f\"  Maintained: {(1 - labels[train_indices]).sum()}\")\n",
    "print(f\"\\nTest label distribution:\")\n",
    "print(f\"  Sycophantic: {labels[test_indices].sum()}\")\n",
    "print(f\"  Maintained: {(1 - labels[test_indices]).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Difference-in-Means (DiM) Direction\n",
    "\n",
    "The simplest way to find a separating direction:\n",
    "\n",
    "$$\\vec{v}_{\\text{sycophancy}} = \\text{mean}(X_{\\text{sycophantic}}) - \\text{mean}(X_{\\text{maintained}})$$\n",
    "\n",
    "This vector points from the \"centroid\" of maintained behavior toward the \"centroid\" of sycophantic behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Compute DiM direction for each layer\n",
    "\n",
    "# Prepare train/test labels\n",
    "train_labels = labels[train_indices]\n",
    "test_labels = labels[test_indices]\n",
    "\n",
    "# Store results\n",
    "dim_directions = {}  # layer -> direction vector\n",
    "dim_scores_test = {}  # layer -> scores on test set\n",
    "\n",
    "print(\"Computing Difference-in-Means directions...\\n\")\n",
    "\n",
    "for layer in data['layers']:\n",
    "    # Get activations for this layer\n",
    "    acts = data['activations'][layer].numpy()\n",
    "    \n",
    "    # Split into train/test\n",
    "    train_acts = acts[train_indices]\n",
    "    test_acts = acts[test_indices]\n",
    "    \n",
    "    # Compute class means on TRAINING data only\n",
    "    train_sycophantic_mask = train_labels == 1\n",
    "    train_maintained_mask = train_labels == 0\n",
    "    \n",
    "    mean_sycophantic = train_acts[train_sycophantic_mask].mean(axis=0)\n",
    "    mean_maintained = train_acts[train_maintained_mask].mean(axis=0)\n",
    "    \n",
    "    # DiM direction: points from maintained toward sycophantic\n",
    "    dim_direction = mean_sycophantic - mean_maintained\n",
    "    \n",
    "    # Normalize to unit vector\n",
    "    dim_direction_norm = np.linalg.norm(dim_direction)\n",
    "    dim_direction_unit = dim_direction / dim_direction_norm\n",
    "    \n",
    "    dim_directions[layer] = dim_direction_unit\n",
    "    \n",
    "    # Score test samples by projecting onto DiM direction\n",
    "    # Higher score = more sycophantic-like\n",
    "    test_scores = test_acts @ dim_direction_unit\n",
    "    dim_scores_test[layer] = test_scores\n",
    "    \n",
    "    print(f\"Layer {layer}:\")\n",
    "    print(f\"  DiM direction norm (before normalizing): {dim_direction_norm:.4f}\")\n",
    "    print(f\"  Mean score (sycophantic): {test_scores[test_labels == 1].mean():.4f}\")\n",
    "    print(f\"  Mean score (maintained): {test_scores[test_labels == 0].mean():.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Compute ROC-AUC for DiM on each layer\n",
    "\n",
    "print(\"ROC-AUC for Difference-in-Means Direction\")\n",
    "print(\"=\" * 50)\n",
    "print()\n",
    "\n",
    "dim_aucs = {}\n",
    "\n",
    "for layer in data['layers']:\n",
    "    scores = dim_scores_test[layer]\n",
    "    auc = roc_auc_score(test_labels, scores)\n",
    "    dim_aucs[layer] = auc\n",
    "    \n",
    "    # Interpret the result\n",
    "    if auc >= 0.8:\n",
    "        status = \"GOOD SIGNAL\"\n",
    "    elif auc >= 0.7:\n",
    "        status = \"WEAK SIGNAL\"\n",
    "    elif auc >= 0.55:\n",
    "        status = \"minimal signal\"\n",
    "    elif auc >= 0.45:\n",
    "        status = \"no signal (random)\"\n",
    "    else:\n",
    "        status = \"inverted (flip direction)\"\n",
    "    \n",
    "    print(f\"Layer {layer:2d}: ROC-AUC = {auc:.4f}  [{status}]\")\n",
    "\n",
    "print()\n",
    "best_layer_dim = max(dim_aucs, key=dim_aucs.get)\n",
    "print(f\"Best layer: {best_layer_dim} (AUC = {dim_aucs[best_layer_dim]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Plot ROC curves for all layers\n",
    "\n",
    "n_layers = len(data['layers'])\n",
    "n_cols = min(3, n_layers)\n",
    "n_rows = (n_layers + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(4 * n_cols, 4 * n_rows))\n",
    "axes = axes.flatten() if n_layers > 1 else [axes]\n",
    "\n",
    "for ax, layer in zip(axes, data['layers']):\n",
    "    scores = dim_scores_test[layer]\n",
    "    fpr, tpr, thresholds = roc_curve(test_labels, scores)\n",
    "    auc = dim_aucs[layer]\n",
    "    \n",
    "    ax.plot(fpr, tpr, 'b-', linewidth=2, label=f'DiM (AUC={auc:.3f})')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random (AUC=0.5)')\n",
    "    ax.fill_between(fpr, tpr, alpha=0.2)\n",
    "    \n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title(f'Layer {layer}')\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.set_xlim([0, 1])\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.set_aspect('equal')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Hide empty subplots\n",
    "for ax in axes[len(data['layers']):]:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('ROC Curves: Difference-in-Means Probe (Sycophancy)', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Logistic Regression Probe\n",
    "\n",
    "Logistic regression learns the optimal separating direction with L2 regularization to prevent overfitting on high-dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Train logistic regression probe for each layer\n",
    "\n",
    "# Use strong regularization (C=0.1) to prevent overfitting\n",
    "C_VALUE = 0.1\n",
    "\n",
    "lr_probes = {}  # layer -> trained LogisticRegression model\n",
    "lr_aucs = {}    # layer -> ROC-AUC on test set\n",
    "\n",
    "print(f\"Training Logistic Regression probes (C={C_VALUE})...\\n\")\n",
    "\n",
    "for layer in data['layers']:\n",
    "    # Get activations\n",
    "    acts = data['activations'][layer].numpy()\n",
    "    train_acts = acts[train_indices]\n",
    "    test_acts = acts[test_indices]\n",
    "    \n",
    "    # Train logistic regression\n",
    "    lr = LogisticRegression(\n",
    "        C=C_VALUE,\n",
    "        penalty='l2',\n",
    "        solver='lbfgs',\n",
    "        max_iter=1000,\n",
    "        random_state=42,\n",
    "    )\n",
    "    lr.fit(train_acts, train_labels)\n",
    "    lr_probes[layer] = lr\n",
    "    \n",
    "    # Predict probabilities on test set\n",
    "    test_probs = lr.predict_proba(test_acts)[:, 1]  # P(sycophantic)\n",
    "    \n",
    "    # Compute ROC-AUC\n",
    "    auc = roc_auc_score(test_labels, test_probs)\n",
    "    lr_aucs[layer] = auc\n",
    "    \n",
    "    # Compare DiM direction with LR weights\n",
    "    dim_dir = dim_directions[layer]\n",
    "    lr_dir = lr.coef_[0] / np.linalg.norm(lr.coef_[0])\n",
    "    cosine_sim = np.dot(dim_dir, lr_dir)\n",
    "    \n",
    "    print(f\"Layer {layer}:\")\n",
    "    print(f\"  LR ROC-AUC: {auc:.4f} (DiM was {dim_aucs[layer]:.4f})\")\n",
    "    print(f\"  Cosine similarity (DiM vs LR direction): {cosine_sim:.4f}\")\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 50)\n",
    "best_layer_lr = max(lr_aucs, key=lr_aucs.get)\n",
    "print(f\"Best layer (LR): {best_layer_lr} (AUC = {lr_aucs[best_layer_lr]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Compare DiM vs Logistic Regression\n",
    "\n",
    "print(\"Comparison: Difference-in-Means vs Logistic Regression\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Layer':<10} {'DiM AUC':<12} {'LR AUC':<12} {'Improvement':<12}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for layer in data['layers']:\n",
    "    dim_auc = dim_aucs[layer]\n",
    "    lr_auc = lr_aucs[layer]\n",
    "    improvement = lr_auc - dim_auc\n",
    "    \n",
    "    print(f\"{layer:<10} {dim_auc:<12.4f} {lr_auc:<12.4f} {improvement:+.4f}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Overall best\n",
    "best_dim = max(dim_aucs.values())\n",
    "best_lr = max(lr_aucs.values())\n",
    "best_overall = max(best_dim, best_lr)\n",
    "\n",
    "print(f\"Best DiM AUC: {best_dim:.4f}\")\n",
    "print(f\"Best LR AUC: {best_lr:.4f}\")\n",
    "print()\n",
    "\n",
    "# Success criteria\n",
    "if best_overall >= 0.7:\n",
    "    print(f\"SUCCESS: Best AUC = {best_overall:.4f} >= 0.7 threshold\")\n",
    "    print(\"Proceed to steering experiment (Notebook 09)\")\n",
    "else:\n",
    "    print(f\"BELOW THRESHOLD: Best AUC = {best_overall:.4f} < 0.7\")\n",
    "    print(\"Consider:\")\n",
    "    print(\"  - Different token position\")\n",
    "    print(\"  - More data\")\n",
    "    print(\"  - Document as informative negative result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## PCA Visualization\n",
    "\n",
    "Project high-dimensional activations to 2D for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: PCA visualization for best layer\n",
    "\n",
    "# Use the layer with best DiM AUC\n",
    "viz_layer = best_layer_dim\n",
    "print(f\"Visualizing layer {viz_layer} (best DiM AUC = {dim_aucs[viz_layer]:.4f})\\n\")\n",
    "\n",
    "# Get all activations for this layer\n",
    "acts = data['activations'][viz_layer].numpy()\n",
    "\n",
    "# Fit PCA on all data\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "acts_2d = pca.fit_transform(acts)\n",
    "\n",
    "print(f\"Variance explained by PC1: {pca.explained_variance_ratio_[0]*100:.1f}%\")\n",
    "print(f\"Variance explained by PC2: {pca.explained_variance_ratio_[1]*100:.1f}%\")\n",
    "print(f\"Total variance explained: {pca.explained_variance_ratio_.sum()*100:.1f}%\")\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Separate by label\n",
    "sycophantic_mask = labels == 1\n",
    "maintained_mask = labels == 0\n",
    "\n",
    "ax.scatter(\n",
    "    acts_2d[maintained_mask, 0], acts_2d[maintained_mask, 1],\n",
    "    c='blue', alpha=0.6, label='Maintained', s=50, edgecolors='white', linewidth=0.5\n",
    ")\n",
    "ax.scatter(\n",
    "    acts_2d[sycophantic_mask, 0], acts_2d[sycophantic_mask, 1],\n",
    "    c='red', alpha=0.6, label='Sycophantic', s=50, edgecolors='white', linewidth=0.5\n",
    ")\n",
    "\n",
    "# Mark test set with different markers\n",
    "test_mask = np.zeros(len(labels), dtype=bool)\n",
    "test_mask[test_indices] = True\n",
    "\n",
    "ax.scatter(\n",
    "    acts_2d[test_mask & maintained_mask, 0], acts_2d[test_mask & maintained_mask, 1],\n",
    "    c='blue', marker='s', s=80, edgecolors='black', linewidth=1.5, label='Maintained (test)'\n",
    ")\n",
    "ax.scatter(\n",
    "    acts_2d[test_mask & sycophantic_mask, 0], acts_2d[test_mask & sycophantic_mask, 1],\n",
    "    c='red', marker='s', s=80, edgecolors='black', linewidth=1.5, label='Sycophantic (test)'\n",
    ")\n",
    "\n",
    "ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% variance)')\n",
    "ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% variance)')\n",
    "ax.set_title(f'PCA of Layer {viz_layer} Activations\\n(Circles=train, Squares=test)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Visualize DiM direction in PCA space\n",
    "\n",
    "# Get class centroids\n",
    "mean_maintained = acts[maintained_mask].mean(axis=0)\n",
    "mean_sycophantic = acts[sycophantic_mask].mean(axis=0)\n",
    "mean_maintained_2d = pca.transform(mean_maintained.reshape(1, -1))[0]\n",
    "mean_sycophantic_2d = pca.transform(mean_sycophantic.reshape(1, -1))[0]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Plot data points (faded)\n",
    "ax.scatter(\n",
    "    acts_2d[maintained_mask, 0], acts_2d[maintained_mask, 1],\n",
    "    c='blue', alpha=0.3, s=30, label='Maintained'\n",
    ")\n",
    "ax.scatter(\n",
    "    acts_2d[sycophantic_mask, 0], acts_2d[sycophantic_mask, 1],\n",
    "    c='red', alpha=0.3, s=30, label='Sycophantic'\n",
    ")\n",
    "\n",
    "# Plot centroids\n",
    "ax.scatter(\n",
    "    mean_maintained_2d[0], mean_maintained_2d[1],\n",
    "    c='blue', s=200, marker='*', edgecolors='black', linewidth=2,\n",
    "    label='Maintained centroid', zorder=5\n",
    ")\n",
    "ax.scatter(\n",
    "    mean_sycophantic_2d[0], mean_sycophantic_2d[1],\n",
    "    c='red', s=200, marker='*', edgecolors='black', linewidth=2,\n",
    "    label='Sycophantic centroid', zorder=5\n",
    ")\n",
    "\n",
    "# Draw arrow for DiM direction (from maintained to sycophantic centroid)\n",
    "ax.annotate(\n",
    "    '', xy=mean_sycophantic_2d, xytext=mean_maintained_2d,\n",
    "    arrowprops=dict(arrowstyle='->', color='green', lw=3),\n",
    ")\n",
    "ax.text(\n",
    "    (mean_maintained_2d[0] + mean_sycophantic_2d[0]) / 2,\n",
    "    (mean_maintained_2d[1] + mean_sycophantic_2d[1]) / 2 + 0.5,\n",
    "    'Sycophancy direction', fontsize=12, color='green', ha='center'\n",
    ")\n",
    "\n",
    "ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% variance)')\n",
    "ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% variance)')\n",
    "ax.set_title(f'Layer {viz_layer}: Sycophancy Direction (centroid to centroid)')\n",
    "ax.legend(loc='best')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## Save Probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Save probes\n",
    "probes_dir = RUN_DIR / \"probes\"\n",
    "probes_dir.mkdir(exist_ok=True)\n",
    "\n",
    "save_path = probes_dir / \"sycophancy_probes.pt\"\n",
    "\n",
    "save_data = {\n",
    "    \"model_name\": data['model_name'],\n",
    "    \"layers\": data['layers'],\n",
    "    \"token_position\": data.get('token_position', 'unknown'),\n",
    "    \"dim_directions\": dim_directions,\n",
    "    \"dim_aucs\": dim_aucs,\n",
    "    \"lr_weights\": {layer: lr_probes[layer].coef_[0] for layer in data['layers']},\n",
    "    \"lr_biases\": {layer: lr_probes[layer].intercept_[0] for layer in data['layers']},\n",
    "    \"lr_aucs\": lr_aucs,\n",
    "    \"best_layer_dim\": best_layer_dim,\n",
    "    \"best_layer_lr\": best_layer_lr,\n",
    "    \"train_indices\": train_indices,\n",
    "    \"test_indices\": test_indices,\n",
    "    \"n_train\": len(train_indices),\n",
    "    \"n_test\": len(test_indices),\n",
    "    \"training_timestamp\": datetime.now().isoformat(),\n",
    "}\n",
    "\n",
    "torch.save(save_data, save_path)\n",
    "print(f\"Saved probes to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Validation - load and verify\n",
    "\n",
    "loaded = torch.load(save_path)\n",
    "\n",
    "print(\"Validation - loaded probe data:\")\n",
    "print(f\"  Model: {loaded['model_name']}\")\n",
    "print(f\"  Layers: {loaded['layers']}\")\n",
    "print(f\"  Best layer (DiM): {loaded['best_layer_dim']} (AUC={loaded['dim_aucs'][loaded['best_layer_dim']]:.4f})\")\n",
    "print(f\"  Best layer (LR): {loaded['best_layer_lr']} (AUC={loaded['lr_aucs'][loaded['best_layer_lr']]:.4f})\")\n",
    "print(f\"  Train/test split: {loaded['n_train']}/{loaded['n_test']}\")\n",
    "print(f\"\\nDiM direction shapes:\")\n",
    "for layer, direction in loaded['dim_directions'].items():\n",
    "    print(f\"  Layer {layer}: {direction.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Probe training complete! Results saved to:\n",
    "```\n",
    "experiments/run_XXXXXX_sycophancy/probes/sycophancy_probes.pt\n",
    "```\n",
    "\n",
    "**Contents:**\n",
    "- `dim_directions`: DiM direction vectors (unit normalized) per layer\n",
    "- `dim_aucs`: ROC-AUC scores for DiM method\n",
    "- `lr_weights`, `lr_biases`: Logistic regression probe weights\n",
    "- `lr_aucs`: ROC-AUC scores for LR method\n",
    "\n",
    "**Next steps (Notebook 09: Steering):**\n",
    "1. Load the sycophancy direction from best layer\n",
    "2. Apply directional ablation during generation\n",
    "3. Test if ablation reduces sycophancy rate\n",
    "4. Report primary (held-out) and secondary (all samples) metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Print paths for next notebook\n",
    "print(f\"\\nFor notebook 09, use:\")\n",
    "print(f'RUN_DIR = Path(\"{RUN_DIR}\")')\n",
    "print(f'PROBES_PATH = RUN_DIR / \"probes/sycophancy_probes.pt\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: Save plot\n",
    "plots_dir = RUN_DIR / \"plots\"\n",
    "plots_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Re-create and save the PCA plot\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.scatter(acts_2d[maintained_mask, 0], acts_2d[maintained_mask, 1],\n",
    "           c='blue', alpha=0.6, label='Maintained', s=50)\n",
    "ax.scatter(acts_2d[sycophantic_mask, 0], acts_2d[sycophantic_mask, 1],\n",
    "           c='red', alpha=0.6, label='Sycophantic', s=50)\n",
    "ax.scatter(mean_maintained_2d[0], mean_maintained_2d[1],\n",
    "           c='blue', s=200, marker='*', edgecolors='black', linewidth=2, label='Maintained centroid')\n",
    "ax.scatter(mean_sycophantic_2d[0], mean_sycophantic_2d[1],\n",
    "           c='red', s=200, marker='*', edgecolors='black', linewidth=2, label='Sycophantic centroid')\n",
    "ax.annotate('', xy=mean_sycophantic_2d, xytext=mean_maintained_2d,\n",
    "            arrowprops=dict(arrowstyle='->', color='green', lw=3))\n",
    "ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% variance)')\n",
    "ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% variance)')\n",
    "ax.set_title(f'Sycophancy Direction - Layer {viz_layer} (AUC={dim_aucs[viz_layer]:.3f})')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(plots_dir / \"sycophancy_pca.png\", dpi=150)\n",
    "print(f\"Saved plot to: {plots_dir / 'sycophancy_pca.png'}\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 17: (Optional) Push to GitHub\n",
    "# Uncomment to save probes to repo\n",
    "\n",
    "# !git add experiments/\n",
    "# !git commit -m \"Add sycophancy probes from notebook 08\"\n",
    "# !git push"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
