{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nawidayima/IPHR_Direction/blob/main/notebooks/04_train_probes.ipynb)\n",
    "\n",
    "# Train Linear Probes for Rationalization Detection\n",
    "\n",
    "**Goal:** Find a direction in activation space that separates \"rationalization\" from \"honest\" reasoning.\n",
    "\n",
    "**Project Plan Reference:** Phase 2, Hours 8-14\n",
    "\n",
    "**Key methods:**\n",
    "1. **Difference-in-Means (DiM):** Simple baseline - find the direction between class centroids\n",
    "2. **Logistic Regression:** Learn the optimal separating direction with regularization\n",
    "\n",
    "**Success criteria:**\n",
    "- ROC-AUC > 0.7 = weak signal\n",
    "- ROC-AUC > 0.8 = good signal (target)\n",
    "\n",
    "**Setup:** Run Cell 0 once to install dependencies, then restart runtime and run from Cell 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 0: Setup - Clone repo and install dependencies\n",
    "# NOTE: After running this cell, RESTART RUNTIME (Runtime > Restart runtime)\n",
    "#       Then skip this cell and run from Cell 1 onwards\n",
    "\n",
    "import os\n",
    "\n",
    "# Clone repo (only if not already cloned)\n",
    "if not os.path.exists('/content/IPHR_Direction'):\n",
    "    !git clone https://github.com/nawidayima/IPHR_Direction.git\n",
    "    %cd /content/IPHR_Direction\n",
    "else:\n",
    "    %cd /content/IPHR_Direction\n",
    "    !git pull  # Get latest changes\n",
    "\n",
    "# Install dependencies\n",
    "!pip install torch numpy pandas scikit-learn matplotlib -q\n",
    "\n",
    "# Install package in editable mode\n",
    "!pip install -e . -q\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Setup complete! Restart runtime and run from Cell 1.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Scikit-learn for ML\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Imports complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Device check\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# For this notebook, we mainly use CPU since probe training is fast\n",
    "# The heavy lifting (activation extraction) was done in notebook 03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Activations\n",
    "\n",
    "We load the pre-extracted activations from notebook 03. The data structure is:\n",
    "\n",
    "```\n",
    "{\n",
    "    'activations': {layer_idx: Tensor[n_samples, d_model]},\n",
    "    'labels': Tensor[n_samples],  # 1=contradiction, 0=honest\n",
    "    'metadata': [{'pair_id', 'domain', 'question_type'}, ...]\n",
    "}\n",
    "```\n",
    "\n",
    "Each question pair contributes 2 samples (question A and question B), both with the same label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Load activations\n",
    "# Ensure we're in the right directory\n",
    "%cd /content/IPHR_Direction\n",
    "\n",
    "RUN_DIR = Path(\"experiments/run_20251228_204835_expand_dataset\")\n",
    "ACTIVATIONS_PATH = RUN_DIR / \"activations/residual_stream_activations.pt\"\n",
    "\n",
    "data = torch.load(ACTIVATIONS_PATH)\n",
    "\n",
    "print(\"Loaded activation data:\")\n",
    "print(f\"  Model: {data['model_name']}\")\n",
    "print(f\"  Layers: {data['layers']}\")\n",
    "print(f\"  d_model: {data['d_model']}\")\n",
    "print(f\"  n_pairs: {data['n_pairs']}\")\n",
    "print(f\"  n_samples: {data['n_samples']}\")\n",
    "print(f\"\\nActivation shapes:\")\n",
    "for layer, acts in data['activations'].items():\n",
    "    print(f\"  Layer {layer}: {acts.shape}\")\n",
    "print(f\"\\nLabels: {data['labels'].shape}\")\n",
    "print(f\"  Contradictions (1): {data['labels'].sum().item()}\")\n",
    "print(f\"  Honest (0): {(~data['labels'].bool()).sum().item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Methodological Choices (per project-plan.md, Hours 6-8)\n\n**Token position:** Last token of prompt (decision point before generation)\n- This is the moment the model \"commits\" to its reasoning strategy\n- Matches Arditi et al.'s most common choice (Table 5: `i* = -1` for 10/13 models)\n\n**Layers:** Upper third [24, 28, 31] of 32 total\n- High-level semantic features emerge in later layers\n- Consistent with Arditi et al. findings: directions typically found at `l*/L ≈ 0.5-0.8`\n\n**Rationale:** Start simple. If ROC-AUC < 0.7, *then* sweep positions/layers (Hour 12-14 contingency).",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Display label distribution by domain\n",
    "metadata = data['metadata']\n",
    "labels = data['labels'].numpy()\n",
    "\n",
    "# Count by domain and label\n",
    "domain_counts = {}\n",
    "for m, label in zip(metadata, labels):\n",
    "    domain = m['domain']\n",
    "    if domain not in domain_counts:\n",
    "        domain_counts[domain] = {'contradiction': 0, 'honest': 0}\n",
    "    if label == 1:\n",
    "        domain_counts[domain]['contradiction'] += 1\n",
    "    else:\n",
    "        domain_counts[domain]['honest'] += 1\n",
    "\n",
    "print(\"Distribution by domain:\")\n",
    "print(\"-\" * 40)\n",
    "for domain, counts in sorted(domain_counts.items()):\n",
    "    total = counts['contradiction'] + counts['honest']\n",
    "    print(f\"{domain:12s}: {counts['contradiction']:3d} contradiction, {counts['honest']:3d} honest (total: {total})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split\n",
    "\n",
    "### Why split by pair_id?\n",
    "\n",
    "Each question pair generates 2 samples (A and B) with the **same label** and **correlated activations**. If we split randomly:\n",
    "- Question A might end up in train\n",
    "- Question B (same pair) might end up in test\n",
    "- The probe could \"cheat\" by memorizing pair-specific patterns\n",
    "\n",
    "**Solution:** Split by `pair_id` so both A and B from the same pair stay together.\n",
    "\n",
    "```\n",
    "80% of pairs → train (both A and B samples)\n",
    "20% of pairs → test (both A and B samples)\n",
    "```\n",
    "\n",
    "This gives a more honest estimate of generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Train/test split by pair_id\n",
    "\n",
    "# Extract pair_ids and domains for stratification\n",
    "pair_ids = np.array([m['pair_id'] for m in metadata])\n",
    "domains = np.array([m['domain'] for m in metadata])\n",
    "\n",
    "# Get unique pairs and their properties\n",
    "unique_pairs = []\n",
    "pair_to_indices = {}\n",
    "pair_to_label = {}\n",
    "pair_to_domain = {}\n",
    "\n",
    "for i, (pid, domain, label) in enumerate(zip(pair_ids, domains, labels)):\n",
    "    if pid not in pair_to_indices:\n",
    "        unique_pairs.append(pid)\n",
    "        pair_to_indices[pid] = []\n",
    "        pair_to_label[pid] = label\n",
    "        pair_to_domain[pid] = domain\n",
    "    pair_to_indices[pid].append(i)\n",
    "\n",
    "print(f\"Total unique pairs: {len(unique_pairs)}\")\n",
    "\n",
    "# Create arrays for splitting\n",
    "unique_pairs = np.array(unique_pairs)\n",
    "pair_labels = np.array([pair_to_label[pid] for pid in unique_pairs])\n",
    "pair_domains = np.array([pair_to_domain[pid] for pid in unique_pairs])\n",
    "\n",
    "# Use GroupShuffleSplit to split by pair while stratifying by label\n",
    "# We use pair_id as both the index and group\n",
    "splitter = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split based on pairs\n",
    "train_pair_idx, test_pair_idx = next(splitter.split(unique_pairs, pair_labels, groups=unique_pairs))\n",
    "\n",
    "train_pairs = set(unique_pairs[train_pair_idx])\n",
    "test_pairs = set(unique_pairs[test_pair_idx])\n",
    "\n",
    "# Map back to sample indices\n",
    "train_indices = []\n",
    "test_indices = []\n",
    "\n",
    "for pid in unique_pairs:\n",
    "    if pid in train_pairs:\n",
    "        train_indices.extend(pair_to_indices[pid])\n",
    "    else:\n",
    "        test_indices.extend(pair_to_indices[pid])\n",
    "\n",
    "train_indices = np.array(train_indices)\n",
    "test_indices = np.array(test_indices)\n",
    "\n",
    "print(f\"\\nSplit results:\")\n",
    "print(f\"  Train pairs: {len(train_pairs)} → {len(train_indices)} samples\")\n",
    "print(f\"  Test pairs: {len(test_pairs)} → {len(test_indices)} samples\")\n",
    "print(f\"\\nTrain label distribution:\")\n",
    "print(f\"  Contradiction: {labels[train_indices].sum()}\")\n",
    "print(f\"  Honest: {(1 - labels[train_indices]).sum()}\")\n",
    "print(f\"\\nTest label distribution:\")\n",
    "print(f\"  Contradiction: {labels[test_indices].sum()}\")\n",
    "print(f\"  Honest: {(1 - labels[test_indices]).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference-in-Means (DiM) Direction\n",
    "\n",
    "### Mathematical Foundation\n",
    "\n",
    "The simplest way to find a separating direction is **difference-in-means**:\n",
    "\n",
    "$$\\vec{v}_{\\text{rationalization}} = \\text{mean}(X_{\\text{contradiction}}) - \\text{mean}(X_{\\text{honest}})$$\n",
    "\n",
    "**Intuition:** This vector points from the \"centroid\" of honest activations toward the \"centroid\" of contradiction activations in 4096-dimensional space.\n",
    "\n",
    "### How to classify with DiM\n",
    "\n",
    "To score a new activation $\\vec{x}$, we compute the **dot product** (projection):\n",
    "\n",
    "$$\\text{score} = \\vec{x} \\cdot \\vec{v}_{\\text{rationalization}}$$\n",
    "\n",
    "**What the dot product means:**\n",
    "- It measures \"how much of $\\vec{x}$ lies in the direction of $\\vec{v}$\"\n",
    "- Higher score → activation is more \"contradiction-like\"\n",
    "- Lower score → activation is more \"honest-like\"\n",
    "\n",
    "**Why this works:** If the two classes form separate clusters, the line connecting their centers is a natural separating direction. Points projected onto this line will cluster by class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Compute DiM direction for each layer\n",
    "\n",
    "# Prepare train/test data\n",
    "train_labels = labels[train_indices]\n",
    "test_labels = labels[test_indices]\n",
    "\n",
    "# Store results\n",
    "dim_directions = {}  # layer -> direction vector\n",
    "dim_scores_test = {}  # layer -> scores on test set\n",
    "\n",
    "print(\"Computing Difference-in-Means directions...\\n\")\n",
    "\n",
    "for layer in data['layers']:\n",
    "    # Get activations for this layer\n",
    "    acts = data['activations'][layer].numpy()\n",
    "    \n",
    "    # Split into train/test\n",
    "    train_acts = acts[train_indices]\n",
    "    test_acts = acts[test_indices]\n",
    "    \n",
    "    # Compute class means on TRAINING data only\n",
    "    train_contradiction_mask = train_labels == 1\n",
    "    train_honest_mask = train_labels == 0\n",
    "    \n",
    "    mean_contradiction = train_acts[train_contradiction_mask].mean(axis=0)\n",
    "    mean_honest = train_acts[train_honest_mask].mean(axis=0)\n",
    "    \n",
    "    # DiM direction: points from honest toward contradiction\n",
    "    dim_direction = mean_contradiction - mean_honest\n",
    "    \n",
    "    # Normalize to unit vector (optional but helps interpretation)\n",
    "    dim_direction_norm = np.linalg.norm(dim_direction)\n",
    "    dim_direction_unit = dim_direction / dim_direction_norm\n",
    "    \n",
    "    dim_directions[layer] = dim_direction_unit\n",
    "    \n",
    "    # Score test samples by projecting onto DiM direction\n",
    "    # Higher score = more contradiction-like\n",
    "    test_scores = test_acts @ dim_direction_unit\n",
    "    dim_scores_test[layer] = test_scores\n",
    "    \n",
    "    print(f\"Layer {layer}:\")\n",
    "    print(f\"  DiM direction norm (before normalizing): {dim_direction_norm:.4f}\")\n",
    "    print(f\"  Mean score (contradiction): {test_scores[test_labels == 1].mean():.4f}\")\n",
    "    print(f\"  Mean score (honest): {test_scores[test_labels == 0].mean():.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC-AUC Evaluation\n",
    "\n",
    "### What is ROC-AUC?\n",
    "\n",
    "**ROC** = Receiver Operating Characteristic curve  \n",
    "**AUC** = Area Under the Curve\n",
    "\n",
    "ROC-AUC measures how well our scores **rank** samples by class, regardless of threshold.\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "| ROC-AUC | Meaning |\n",
    "|---------|----------|\n",
    "| 0.5 | Random guessing (no signal) |\n",
    "| 0.7 | Weak signal |\n",
    "| 0.8 | Good signal (our target) |\n",
    "| 1.0 | Perfect separation |\n",
    "\n",
    "### Intuitive explanation\n",
    "\n",
    "ROC-AUC answers: **\"If I pick one contradiction sample and one honest sample at random, how often does the probe correctly rank the contradiction higher?\"**\n",
    "\n",
    "- AUC = 0.5 → 50% of the time (coin flip)\n",
    "- AUC = 0.8 → 80% of the time\n",
    "- AUC = 1.0 → 100% of the time\n",
    "\n",
    "### Why ROC-AUC instead of accuracy?\n",
    "\n",
    "Accuracy requires choosing a threshold. ROC-AUC is **threshold-free** - it evaluates the entire ranking. This is better when:\n",
    "- We don't know the optimal threshold yet\n",
    "- We want to compare methods fairly\n",
    "- The class distribution might differ at deployment time"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Detection vs. Intervention: Why We Don't Need Arditi's Full Sweep\n",
    "\n",
    "**Arditi et al.'s approach:** Exhaustive search over all layers × all post-instruction token positions, selecting the best direction via validation metrics (`bypass_score`, `induce_score`, `kl_score`).\n",
    "\n",
    "**Why that level of rigor?** Their goal is *intervention*—ablating a direction must reliably disable refusal. The optimal direction matters for causal effect.\n",
    "\n",
    "**Our goal is *detection*** (classification). A strong signal (AUC > 0.8) at *any* reasonable position is sufficient evidence for H1. We don't need the globally optimal direction, just one that separates the classes.\n",
    "\n",
    "**Decision rule:**\n",
    "- AUC ≥ 0.8 → Proceed to confounder check (Hour 10-12)\n",
    "- 0.7 ≤ AUC < 0.8 → Try logistic regression (this notebook)\n",
    "- AUC < 0.7 → Consider position sweep (first generated token) or layer sweep"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Compute ROC-AUC for DiM on each layer\n",
    "\n",
    "print(\"ROC-AUC for Difference-in-Means Direction\")\n",
    "print(\"=\" * 45)\n",
    "print()\n",
    "\n",
    "dim_aucs = {}\n",
    "\n",
    "for layer in data['layers']:\n",
    "    scores = dim_scores_test[layer]\n",
    "    auc = roc_auc_score(test_labels, scores)\n",
    "    dim_aucs[layer] = auc\n",
    "    \n",
    "    # Interpret the result\n",
    "    if auc >= 0.8:\n",
    "        status = \"GOOD SIGNAL\"\n",
    "    elif auc >= 0.7:\n",
    "        status = \"WEAK SIGNAL\"\n",
    "    elif auc >= 0.5:\n",
    "        status = \"minimal signal\"\n",
    "    else:\n",
    "        status = \"inverted (flip direction)\"\n",
    "    \n",
    "    print(f\"Layer {layer}: ROC-AUC = {auc:.4f}  [{status}]\")\n",
    "\n",
    "print()\n",
    "best_layer = max(dim_aucs, key=dim_aucs.get)\n",
    "print(f\"Best layer: {best_layer} (AUC = {dim_aucs[best_layer]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Plot ROC curves for all layers\n",
    "\n",
    "fig, axes = plt.subplots(1, len(data['layers']), figsize=(4 * len(data['layers']), 4))\n",
    "\n",
    "for ax, layer in zip(axes, data['layers']):\n",
    "    scores = dim_scores_test[layer]\n",
    "    fpr, tpr, thresholds = roc_curve(test_labels, scores)\n",
    "    auc = dim_aucs[layer]\n",
    "    \n",
    "    ax.plot(fpr, tpr, 'b-', linewidth=2, label=f'DiM (AUC={auc:.3f})')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random (AUC=0.5)')\n",
    "    ax.fill_between(fpr, tpr, alpha=0.2)\n",
    "    \n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title(f'Layer {layer}')\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.set_xlim([0, 1])\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.set_aspect('equal')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('ROC Curves: Difference-in-Means Probe', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Probe\n",
    "\n",
    "### Why logistic regression?\n",
    "\n",
    "Difference-in-Means finds **a** separating direction (the line between centroids), but not necessarily the **optimal** one.\n",
    "\n",
    "Logistic regression learns the direction that maximizes classification performance:\n",
    "\n",
    "$$P(\\text{contradiction} | \\vec{x}) = \\sigma(\\vec{w} \\cdot \\vec{x} + b)$$\n",
    "\n",
    "where $\\sigma(z) = \\frac{1}{1 + e^{-z}}$ is the sigmoid function.\n",
    "\n",
    "### The overfitting problem\n",
    "\n",
    "Our activations are 4096-dimensional, but we only have ~150 training samples. This is a classic \"p >> n\" problem where overfitting is a serious risk.\n",
    "\n",
    "### L2 Regularization\n",
    "\n",
    "We add a penalty term that shrinks weights toward zero:\n",
    "\n",
    "$$\\text{Loss} = \\text{CrossEntropy} + \\lambda ||\\vec{w}||^2$$\n",
    "\n",
    "- **High $\\lambda$** → Stronger regularization → Weights stay small → More like DiM direction\n",
    "- **Low $\\lambda$** → Weaker regularization → Weights can grow → Risk of overfitting\n",
    "\n",
    "In sklearn, `C = 1/λ`, so:\n",
    "- **Small C** (e.g., 0.01) → Strong regularization\n",
    "- **Large C** (e.g., 100) → Weak regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Train logistic regression probe for each layer\n",
    "\n",
    "# Use strong regularization (C=0.1) to prevent overfitting on high-dimensional data\n",
    "# This is especially important when n_samples << n_features\n",
    "C_VALUE = 0.1  # Regularization strength (smaller = stronger regularization)\n",
    "\n",
    "lr_probes = {}  # layer -> trained LogisticRegression model\n",
    "lr_aucs = {}    # layer -> ROC-AUC on test set\n",
    "\n",
    "print(f\"Training Logistic Regression probes (C={C_VALUE})...\\n\")\n",
    "\n",
    "for layer in data['layers']:\n",
    "    # Get activations\n",
    "    acts = data['activations'][layer].numpy()\n",
    "    train_acts = acts[train_indices]\n",
    "    test_acts = acts[test_indices]\n",
    "    \n",
    "    # Train logistic regression\n",
    "    lr = LogisticRegression(\n",
    "        C=C_VALUE,\n",
    "        penalty='l2',\n",
    "        solver='lbfgs',\n",
    "        max_iter=1000,\n",
    "        random_state=42,\n",
    "    )\n",
    "    lr.fit(train_acts, train_labels)\n",
    "    lr_probes[layer] = lr\n",
    "    \n",
    "    # Predict probabilities on test set\n",
    "    test_probs = lr.predict_proba(test_acts)[:, 1]  # P(contradiction)\n",
    "    \n",
    "    # Compute ROC-AUC\n",
    "    auc = roc_auc_score(test_labels, test_probs)\n",
    "    lr_aucs[layer] = auc\n",
    "    \n",
    "    # Compare DiM direction with LR weights\n",
    "    dim_dir = dim_directions[layer]\n",
    "    lr_dir = lr.coef_[0] / np.linalg.norm(lr.coef_[0])\n",
    "    cosine_sim = np.dot(dim_dir, lr_dir)\n",
    "    \n",
    "    print(f\"Layer {layer}:\")\n",
    "    print(f\"  LR ROC-AUC: {auc:.4f} (DiM was {dim_aucs[layer]:.4f})\")\n",
    "    print(f\"  Cosine similarity (DiM vs LR direction): {cosine_sim:.4f}\")\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 50)\n",
    "best_layer_lr = max(lr_aucs, key=lr_aucs.get)\n",
    "print(f\"Best layer (LR): {best_layer_lr} (AUC = {lr_aucs[best_layer_lr]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Compare DiM vs Logistic Regression\n",
    "\n",
    "print(\"Comparison: Difference-in-Means vs Logistic Regression\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"{'Layer':<10} {'DiM AUC':<12} {'LR AUC':<12} {'Improvement':<12}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for layer in data['layers']:\n",
    "    dim_auc = dim_aucs[layer]\n",
    "    lr_auc = lr_aucs[layer]\n",
    "    improvement = lr_auc - dim_auc\n",
    "    \n",
    "    print(f\"{layer:<10} {dim_auc:<12.4f} {lr_auc:<12.4f} {improvement:+.4f}\")\n",
    "\n",
    "print()\n",
    "print(\"Note: If improvement is small, DiM direction is already near-optimal.\")\n",
    "print(\"Large improvement suggests the optimal direction differs from class centroids.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Visualization\n",
    "\n",
    "### What is PCA?\n",
    "\n",
    "**Principal Component Analysis** projects high-dimensional data (4096D) to low dimensions (2D) while preserving as much variance as possible.\n",
    "\n",
    "The first principal component (PC1) is the direction of maximum variance.  \n",
    "The second (PC2) is perpendicular to PC1 and captures the next most variance.\n",
    "\n",
    "### Important caveat\n",
    "\n",
    "PCA is for **visualization only**, not analysis!\n",
    "\n",
    "If classes overlap in 2D PCA, they may still be perfectly separable in the full 4096D space. The separating direction might be orthogonal to the high-variance directions that PCA finds.\n",
    "\n",
    "**Rule of thumb:**\n",
    "- Classes separate in PCA → Good (probe should work well)\n",
    "- Classes overlap in PCA → Inconclusive (probe might still work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: PCA visualization for best layer\n",
    "\n",
    "# Use the layer with best DiM AUC\n",
    "viz_layer = best_layer\n",
    "print(f\"Visualizing layer {viz_layer} (best DiM AUC = {dim_aucs[viz_layer]:.4f})\\n\")\n",
    "\n",
    "# Get all activations for this layer\n",
    "acts = data['activations'][viz_layer].numpy()\n",
    "\n",
    "# Fit PCA on all data\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "acts_2d = pca.fit_transform(acts)\n",
    "\n",
    "print(f\"Variance explained by PC1: {pca.explained_variance_ratio_[0]*100:.1f}%\")\n",
    "print(f\"Variance explained by PC2: {pca.explained_variance_ratio_[1]*100:.1f}%\")\n",
    "print(f\"Total variance explained: {pca.explained_variance_ratio_.sum()*100:.1f}%\")\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Separate by label\n",
    "contradiction_mask = labels == 1\n",
    "honest_mask = labels == 0\n",
    "\n",
    "ax.scatter(\n",
    "    acts_2d[honest_mask, 0], acts_2d[honest_mask, 1],\n",
    "    c='blue', alpha=0.6, label='Honest', s=50, edgecolors='white', linewidth=0.5\n",
    ")\n",
    "ax.scatter(\n",
    "    acts_2d[contradiction_mask, 0], acts_2d[contradiction_mask, 1],\n",
    "    c='red', alpha=0.6, label='Contradiction', s=50, edgecolors='white', linewidth=0.5\n",
    ")\n",
    "\n",
    "# Mark test set with different markers\n",
    "test_mask = np.zeros(len(labels), dtype=bool)\n",
    "test_mask[test_indices] = True\n",
    "\n",
    "ax.scatter(\n",
    "    acts_2d[test_mask & honest_mask, 0], acts_2d[test_mask & honest_mask, 1],\n",
    "    c='blue', marker='s', s=80, edgecolors='black', linewidth=1.5, label='Honest (test)'\n",
    ")\n",
    "ax.scatter(\n",
    "    acts_2d[test_mask & contradiction_mask, 0], acts_2d[test_mask & contradiction_mask, 1],\n",
    "    c='red', marker='s', s=80, edgecolors='black', linewidth=1.5, label='Contradiction (test)'\n",
    ")\n",
    "\n",
    "ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% variance)')\n",
    "ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% variance)')\n",
    "ax.set_title(f'PCA of Layer {viz_layer} Activations\\n(Circles=train, Squares=test)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Visualize DiM direction in PCA space\n",
    "\n",
    "# Project the DiM direction onto PCA\n",
    "dim_dir = dim_directions[viz_layer]\n",
    "dim_dir_2d = pca.transform(dim_dir.reshape(1, -1))[0]\n",
    "\n",
    "# Also get class centroids\n",
    "mean_honest = acts[honest_mask].mean(axis=0)\n",
    "mean_contradiction = acts[contradiction_mask].mean(axis=0)\n",
    "mean_honest_2d = pca.transform(mean_honest.reshape(1, -1))[0]\n",
    "mean_contradiction_2d = pca.transform(mean_contradiction.reshape(1, -1))[0]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Plot data points (faded)\n",
    "ax.scatter(\n",
    "    acts_2d[honest_mask, 0], acts_2d[honest_mask, 1],\n",
    "    c='blue', alpha=0.3, s=30, label='Honest'\n",
    ")\n",
    "ax.scatter(\n",
    "    acts_2d[contradiction_mask, 0], acts_2d[contradiction_mask, 1],\n",
    "    c='red', alpha=0.3, s=30, label='Contradiction'\n",
    ")\n",
    "\n",
    "# Plot centroids\n",
    "ax.scatter(\n",
    "    mean_honest_2d[0], mean_honest_2d[1],\n",
    "    c='blue', s=200, marker='*', edgecolors='black', linewidth=2,\n",
    "    label='Honest centroid', zorder=5\n",
    ")\n",
    "ax.scatter(\n",
    "    mean_contradiction_2d[0], mean_contradiction_2d[1],\n",
    "    c='red', s=200, marker='*', edgecolors='black', linewidth=2,\n",
    "    label='Contradiction centroid', zorder=5\n",
    ")\n",
    "\n",
    "# Draw arrow for DiM direction (from honest to contradiction centroid)\n",
    "ax.annotate(\n",
    "    '', xy=mean_contradiction_2d, xytext=mean_honest_2d,\n",
    "    arrowprops=dict(arrowstyle='->', color='green', lw=3),\n",
    ")\n",
    "ax.text(\n",
    "    (mean_honest_2d[0] + mean_contradiction_2d[0]) / 2,\n",
    "    (mean_honest_2d[1] + mean_contradiction_2d[1]) / 2 + 0.5,\n",
    "    'DiM direction', fontsize=12, color='green', ha='center'\n",
    ")\n",
    "\n",
    "ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% variance)')\n",
    "ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% variance)')\n",
    "ax.set_title(f'Layer {viz_layer}: DiM Direction (centroid to centroid)')\n",
    "ax.legend(loc='best')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results\n",
    "\n",
    "Save the trained probes and evaluation metrics for later use (steering experiments in Phase 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\nProbe training complete! Results saved to:\n```\nexperiments/run_20251228_204835_expand_dataset/probes/rationalization_probes.pt\n```\n\n**Contents:**\n- `dim_directions`: DiM direction vectors (unit normalized) per layer\n- `dim_aucs`: ROC-AUC scores for DiM method\n- `lr_weights`, `lr_biases`: Logistic regression probe weights\n- `lr_aucs`: ROC-AUC scores for LR method\n\n---\n\n**Next steps (per project-plan.md):**\n\n1. **Hours 10-12: Confounder Check**\n   - Does the probe fire on incorrect but non-contradictory answers?\n   - If yes → detecting \"wrongness\", not rationalization (confounded)\n   - If no → direction is specific to rationalization\n\n2. **Hours 14-16: H2 Generalization Test (ICRL)**\n   - Generate ICRL trajectories (correct answer → fake negative feedback)\n   - Test if the same probe detects ICRL-induced rationalization\n\n---\n\n**Deferred to Phase 3 (Hours 16-18): Steering Intervention**\n\nOnce detection is validated, test *causality* via directional ablation:\n\n$$\\mathbf{h}' = \\mathbf{h} - (\\mathbf{h} \\cdot \\hat{\\mathbf{v}}) \\hat{\\mathbf{v}}$$\n\nwhere $\\hat{\\mathbf{v}}$ is the unit rationalization direction (`dim_directions[layer]`).\n\n*Expected result:* Ablating the rationalization direction reduces contradiction rate on held-out pairs.\n\n*Reference:* Arditi et al. Eq. 4 (directional ablation), Eq. 5 (weight orthogonalization—optional for permanent edit)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Validation - load and verify\n",
    "\n",
    "loaded = torch.load(save_path)\n",
    "\n",
    "print(\"Validation - loaded probe data:\")\n",
    "print(f\"  Model: {loaded['model_name']}\")\n",
    "print(f\"  Layers: {loaded['layers']}\")\n",
    "print(f\"  Best layer (DiM): {loaded['best_layer_dim']} (AUC={loaded['dim_aucs'][loaded['best_layer_dim']]:.4f})\")\n",
    "print(f\"  Best layer (LR): {loaded['best_layer_lr']} (AUC={loaded['lr_aucs'][loaded['best_layer_lr']]:.4f})\")\n",
    "print(f\"  Train/test split: {loaded['n_train']}/{loaded['n_test']}\")\n",
    "print(f\"\\nDiM direction shapes:\")\n",
    "for layer, dir in loaded['dim_directions'].items():\n",
    "    print(f\"  Layer {layer}: {dir.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Probe training complete! Results saved to:\n",
    "```\n",
    "experiments/run_20251228_204835_expand_dataset/probes/rationalization_probes.pt\n",
    "```\n",
    "\n",
    "**Contents:**\n",
    "- `dim_directions`: DiM direction vectors (unit normalized) per layer\n",
    "- `dim_aucs`: ROC-AUC scores for DiM method\n",
    "- `lr_weights`, `lr_biases`: Logistic regression probe weights\n",
    "- `lr_aucs`: ROC-AUC scores for LR method\n",
    "\n",
    "**Next steps (per project-plan.md):**\n",
    "\n",
    "1. **Hours 10-12: Confounder Check**\n",
    "   - Does the probe fire on incorrect but non-contradictory answers?\n",
    "   - If yes → detecting \"wrongness\", not rationalization (confounded)\n",
    "   - If no → direction is specific to rationalization\n",
    "\n",
    "2. **Hours 14-16: H2 Generalization Test (ICRL)**\n",
    "   - Generate ICRL trajectories (correct answer → fake negative feedback)\n",
    "   - Test if the same probe detects ICRL-induced rationalization\n",
    "\n",
    "3. **Hours 16-18: Steering Intervention**\n",
    "   - Ablate the rationalization direction during generation\n",
    "   - Test if contradiction rate decreases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: (Optional) Push to GitHub\n",
    "# Uncomment to save probes to repo\n",
    "\n",
    "# !git add experiments/\n",
    "# !git commit -m \"Add trained probes from Phase 2\"\n",
    "# !git push"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
