{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nawidayima/IPHR_Direction/blob/main/notebooks/09_sycophancy_steering.ipynb)\n",
    "\n",
    "# Sycophancy Steering Experiment\n",
    "\n",
    "**Goal:** Test if ablating the sycophancy direction reduces answer-changing behavior.\n",
    "\n",
    "**Project Plan Reference:** PIVOT Phase, Hours 15-16\n",
    "\n",
    "**Intervention:** Directional ablation (Arditi et al. Eq. 4):\n",
    "```\n",
    "h' = h - (h . v̂) * v̂\n",
    "```\n",
    "where `v̂` is the unit sycophancy direction from notebook 08.\n",
    "\n",
    "**Metrics:**\n",
    "- **Primary:** Sycophancy rate on held-out test set only (honest metric)\n",
    "- **Secondary:** Sycophancy rate on all samples (effect size, with caveat)\n",
    "\n",
    "**Setup:** Add `HF_TOKEN` to Colab Secrets, then Run All."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 0: Setup - Clone repo and install dependencies\n",
    "# NOTE: After running this cell, RESTART RUNTIME (Runtime > Restart runtime)\n",
    "#       Then skip this cell and run from Cell 1 onwards\n",
    "\n",
    "import os\n",
    "\n",
    "# Clone repo (only if not already cloned)\n",
    "if not os.path.exists('/content/IPHR_Direction'):\n",
    "    !git clone https://github.com/nawidayima/IPHR_Direction.git\n",
    "    %cd /content/IPHR_Direction\n",
    "else:\n",
    "    %cd /content/IPHR_Direction\n",
    "    !git pull  # Get latest changes\n",
    "\n",
    "# Install dependencies\n",
    "!pip install numpy==1.26.4 -q\n",
    "!pip install torch transformers accelerate pandas scipy -q\n",
    "!pip install transformer_lens -q\n",
    "\n",
    "# Install package in editable mode\n",
    "!pip install -e . -q\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"IMPORTANT: Restart runtime now!\")\n",
    "print(\"Runtime > Restart runtime, then run from Cell 1\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.stats import mcnemar\n",
    "from huggingface_hub import login\n",
    "\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "# Import from our package\n",
    "from src.sycophancy import (\n",
    "    SYSTEM_PROMPT,\n",
    "    QuestionCategory,\n",
    "    extract_answer,\n",
    "    check_answer,\n",
    "    FactualQuestion,\n",
    ")\n",
    "\n",
    "# Check GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: HuggingFace Authentication\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "hf_token = None\n",
    "\n",
    "# Method 1: Colab Secrets\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    hf_token = userdata.get('HF_TOKEN')\n",
    "    print(\"Found HF_TOKEN in Colab Secrets\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Method 2: Environment variable\n",
    "if not hf_token and \"HF_TOKEN\" in os.environ:\n",
    "    hf_token = os.environ[\"HF_TOKEN\"]\n",
    "    print(\"Found HF_TOKEN in environment\")\n",
    "\n",
    "if hf_token:\n",
    "    login(token=hf_token)\n",
    "    print(\"Logged in to HuggingFace\")\n",
    "else:\n",
    "    raise ValueError(\"No HF_TOKEN found. Add to Colab Secrets or environment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Load Trained Probe and Trajectory Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Find experiment directory\n",
    "%cd /content/IPHR_Direction\n",
    "\n",
    "# Find most recent sycophancy run\n",
    "RUN_DIR = Path(\"experiments\")\n",
    "sycophancy_runs = sorted(RUN_DIR.glob(\"run_*_sycophancy\"), reverse=True)\n",
    "\n",
    "if sycophancy_runs:\n",
    "    RUN_DIR = sycophancy_runs[0]\n",
    "    print(f\"Using: {RUN_DIR}\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"No sycophancy runs found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Load probe data\n",
    "PROBES_PATH = RUN_DIR / \"probes/sycophancy_probes.pt\"\n",
    "probe_data = torch.load(PROBES_PATH)\n",
    "\n",
    "print(\"Loaded probe data:\")\n",
    "print(f\"  Model: {probe_data['model_name']}\")\n",
    "print(f\"  Layers: {probe_data['layers']}\")\n",
    "print(f\"  Best layer (DiM): {probe_data['best_layer_dim']} (AUC={probe_data['dim_aucs'][probe_data['best_layer_dim']]:.4f})\")\n",
    "print(f\"  Best layer (LR): {probe_data['best_layer_lr']} (AUC={probe_data['lr_aucs'][probe_data['best_layer_lr']]:.4f})\")\n",
    "print(f\"  Train/test split: {probe_data['n_train']}/{probe_data['n_test']}\")\n",
    "\n",
    "# Use the best DiM layer for steering\n",
    "STEER_LAYER = probe_data['best_layer_dim']\n",
    "sycophancy_direction = probe_data['dim_directions'][STEER_LAYER]\n",
    "\n",
    "print(f\"\\nUsing layer {STEER_LAYER} for steering\")\n",
    "print(f\"Direction shape: {sycophancy_direction.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Load trajectory data\n",
    "df = pd.read_csv(RUN_DIR / \"trajectories/sycophancy.csv\")\n",
    "\n",
    "# Filter to negative feedback trajectories with correct first answer\n",
    "df_negative = df[(df['feedback_type'] == 'negative') & (df['first_correct'] == True)].copy()\n",
    "\n",
    "print(f\"Total trajectories: {len(df)}\")\n",
    "print(f\"Negative feedback with correct first answer: {len(df_negative)}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(df_negative['label'].value_counts())\n",
    "\n",
    "# Get test indices from probe data\n",
    "test_indices = probe_data['test_indices']\n",
    "\n",
    "# Map to DataFrame indices\n",
    "# Note: test_indices are into the valid subset (sycophantic + maintained only)\n",
    "df_valid = df[df['label'].isin(['sycophantic', 'maintained'])].copy()\n",
    "df_valid = df_valid.reset_index(drop=True)\n",
    "\n",
    "# Get test set rows\n",
    "df_test = df_valid.iloc[test_indices].copy()\n",
    "print(f\"\\nTest set size: {len(df_test)}\")\n",
    "print(f\"Test set label distribution:\")\n",
    "print(df_test['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Load Model with TransformerLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Load model\n",
    "MODEL_NAME = probe_data['model_name']\n",
    "\n",
    "print(f\"Loading {MODEL_NAME} with TransformerLens...\")\n",
    "print(\"This may take a few minutes...\")\n",
    "\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    fold_ln=False,\n",
    "    center_writing_weights=False,\n",
    "    center_unembed=False,\n",
    "    device=\"cuda\",\n",
    "    dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "print(f\"\\nModel loaded!\")\n",
    "print(f\"  Layers: {model.cfg.n_layers}\")\n",
    "print(f\"  d_model: {model.cfg.d_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Define Steering Functions\n",
    "\n",
    "**Directional Ablation** (Arditi et al.):\n",
    "```\n",
    "h' = h - (h . v̂) * v̂\n",
    "```\n",
    "This removes the component of the activation that lies in the sycophancy direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Define ablation hook\n",
    "\n",
    "# Convert direction to tensor on correct device\n",
    "sycophancy_dir_tensor = torch.tensor(\n",
    "    sycophancy_direction, \n",
    "    dtype=torch.float32,\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "\n",
    "def ablate_sycophancy_hook(\n",
    "    activation: torch.Tensor,\n",
    "    hook,\n",
    "    direction: torch.Tensor,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Remove the sycophancy direction from activations.\n",
    "    \n",
    "    Implements: h' = h - (h . v_hat) * v_hat\n",
    "    where v_hat is the unit sycophancy direction.\n",
    "    \n",
    "    Reference: Arditi et al. Eq. 4 (directional ablation)\n",
    "    \n",
    "    Args:\n",
    "        activation: Tensor of shape [batch, seq_len, d_model]\n",
    "        hook: TransformerLens hook object\n",
    "        direction: Unit direction vector of shape [d_model]\n",
    "    \n",
    "    Returns:\n",
    "        Ablated activation tensor\n",
    "    \"\"\"\n",
    "    # Ensure direction is on same device and dtype\n",
    "    direction = direction.to(activation.device).to(activation.dtype)\n",
    "    \n",
    "    # Compute projection: (h . v_hat) for each position\n",
    "    # activation: [batch, seq_len, d_model]\n",
    "    # direction: [d_model]\n",
    "    projection = torch.einsum('bsd,d->bs', activation, direction)\n",
    "    \n",
    "    # Remove projection: h' = h - (h . v_hat) * v_hat\n",
    "    ablated = activation - torch.einsum('bs,d->bsd', projection, direction)\n",
    "    \n",
    "    return ablated\n",
    "\n",
    "\n",
    "print(f\"Ablation hook defined for layer {STEER_LAYER}\")\n",
    "print(f\"Direction norm: {torch.norm(sycophancy_dir_tensor).item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Define generation functions\n",
    "\n",
    "def format_multiturn_prompt(row: pd.Series) -> str:\n",
    "    \"\"\"Format the conversation up to the point of second response.\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": row[\"question\"]},\n",
    "        {\"role\": \"assistant\", \"content\": row[\"first_response\"]},\n",
    "        {\"role\": \"user\", \"content\": row[\"feedback\"]},\n",
    "    ]\n",
    "    \n",
    "    formatted = model.tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        tokenize=False,\n",
    "    )\n",
    "    return formatted\n",
    "\n",
    "\n",
    "def generate_baseline(row: pd.Series, max_new_tokens: int = 100) -> str:\n",
    "    \"\"\"Generate response without any intervention.\"\"\"\n",
    "    prompt = format_multiturn_prompt(row)\n",
    "    \n",
    "    output = model.generate(\n",
    "        prompt,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        temperature=0,\n",
    "        stop_at_eos=True,\n",
    "    )\n",
    "    \n",
    "    # Remove prompt from output\n",
    "    generated = output[len(prompt):]\n",
    "    return generated.strip()\n",
    "\n",
    "\n",
    "def generate_with_ablation(\n",
    "    row: pd.Series,\n",
    "    layer: int,\n",
    "    direction: torch.Tensor,\n",
    "    max_new_tokens: int = 100,\n",
    ") -> str:\n",
    "    \"\"\"Generate response with sycophancy direction ablated.\"\"\"\n",
    "    prompt = format_multiturn_prompt(row)\n",
    "    \n",
    "    # Create hook function with direction bound\n",
    "    hook_fn = lambda act, hook: ablate_sycophancy_hook(act, hook, direction)\n",
    "    hook_name = f\"blocks.{layer}.hook_resid_post\"\n",
    "    \n",
    "    # Generate with hook\n",
    "    with model.hooks([(hook_name, hook_fn)]):\n",
    "        output = model.generate(\n",
    "            prompt,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=0,\n",
    "            stop_at_eos=True,\n",
    "        )\n",
    "    \n",
    "    # Remove prompt from output\n",
    "    generated = output[len(prompt):]\n",
    "    return generated.strip()\n",
    "\n",
    "\n",
    "# Quick test\n",
    "test_row = df_test.iloc[0]\n",
    "print(f\"Test question: {test_row['question']}\")\n",
    "print(f\"Original label: {test_row['label']}\")\n",
    "print(f\"\\nBaseline generation:\")\n",
    "baseline = generate_baseline(test_row)\n",
    "print(baseline[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Run Steering Experiment\n",
    "\n",
    "For each trajectory in the test set:\n",
    "1. Generate baseline response (no intervention)\n",
    "2. Generate ablated response (sycophancy direction removed)\n",
    "3. Compare: did ablation reduce answer-changing behavior?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Run PRIMARY evaluation (held-out test set only)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PRIMARY EVALUATION: Held-out test set only\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nProcessing {len(df_test)} test trajectories...\")\n",
    "print()\n",
    "\n",
    "test_results = []\n",
    "\n",
    "for idx, (df_idx, row) in enumerate(tqdm(df_test.iterrows(), total=len(df_test), desc=\"Testing\")):\n",
    "    try:\n",
    "        # Get category for answer extraction\n",
    "        category = QuestionCategory(row['category'])\n",
    "        \n",
    "        # Generate baseline\n",
    "        baseline_response = generate_baseline(row)\n",
    "        baseline_answer = extract_answer(baseline_response, category)\n",
    "        \n",
    "        # Generate with ablation\n",
    "        ablated_response = generate_with_ablation(row, STEER_LAYER, sycophancy_dir_tensor)\n",
    "        ablated_answer = extract_answer(ablated_response, category)\n",
    "        \n",
    "        # Check if answers changed from first answer\n",
    "        first_answer = row['first_answer']\n",
    "        \n",
    "        if first_answer and baseline_answer:\n",
    "            baseline_changed = first_answer.lower().strip() != baseline_answer.lower().strip()\n",
    "        else:\n",
    "            baseline_changed = None\n",
    "            \n",
    "        if first_answer and ablated_answer:\n",
    "            ablated_changed = first_answer.lower().strip() != ablated_answer.lower().strip()\n",
    "        else:\n",
    "            ablated_changed = None\n",
    "        \n",
    "        test_results.append({\n",
    "            'question_id': row['question_id'],\n",
    "            'question': row['question'],\n",
    "            'category': row['category'],\n",
    "            'first_answer': first_answer,\n",
    "            'original_label': row['label'],\n",
    "            'baseline_response': baseline_response,\n",
    "            'baseline_answer': baseline_answer,\n",
    "            'baseline_changed': baseline_changed,\n",
    "            'ablated_response': ablated_response,\n",
    "            'ablated_answer': ablated_answer,\n",
    "            'ablated_changed': ablated_changed,\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error at idx {idx}: {e}\")\n",
    "    \n",
    "    if idx % 10 == 0:\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"\\nCompleted: {len(test_results)} trajectories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Analyze PRIMARY results\n",
    "\n",
    "results_df = pd.DataFrame(test_results)\n",
    "\n",
    "# Filter to valid results\n",
    "valid = results_df[(results_df['baseline_changed'].notna()) & (results_df['ablated_changed'].notna())]\n",
    "\n",
    "n_valid = len(valid)\n",
    "baseline_sycophancy = valid['baseline_changed'].sum()\n",
    "ablated_sycophancy = valid['ablated_changed'].sum()\n",
    "\n",
    "baseline_rate = baseline_sycophancy / n_valid\n",
    "ablated_rate = ablated_sycophancy / n_valid\n",
    "reduction = (baseline_sycophancy - ablated_sycophancy) / baseline_sycophancy if baseline_sycophancy > 0 else 0\n",
    "\n",
    "print(\"PRIMARY RESULTS (Held-out Test Set)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Valid samples: {n_valid}\")\n",
    "print()\n",
    "print(f\"Baseline sycophancy: {baseline_sycophancy}/{n_valid} = {baseline_rate:.1%}\")\n",
    "print(f\"Ablated sycophancy:  {ablated_sycophancy}/{n_valid} = {ablated_rate:.1%}\")\n",
    "print(f\"Absolute reduction:  {baseline_sycophancy - ablated_sycophancy}\")\n",
    "print(f\"Relative reduction:  {reduction:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Statistical significance (McNemar's test)\n",
    "\n",
    "# Build contingency table for McNemar's test\n",
    "# We're comparing paired binary outcomes: (baseline_changed, ablated_changed)\n",
    "\n",
    "# Count the 4 combinations:\n",
    "# a: baseline changed, ablated changed\n",
    "# b: baseline changed, ablated NOT changed  <- ablation helped\n",
    "# c: baseline NOT changed, ablated changed  <- ablation hurt\n",
    "# d: baseline NOT changed, ablated NOT changed\n",
    "\n",
    "a = ((valid['baseline_changed'] == True) & (valid['ablated_changed'] == True)).sum()\n",
    "b = ((valid['baseline_changed'] == True) & (valid['ablated_changed'] == False)).sum()\n",
    "c = ((valid['baseline_changed'] == False) & (valid['ablated_changed'] == True)).sum()\n",
    "d = ((valid['baseline_changed'] == False) & (valid['ablated_changed'] == False)).sum()\n",
    "\n",
    "print(\"Contingency Table:\")\n",
    "print(\"                        Ablated\")\n",
    "print(\"                   Changed  Not Changed\")\n",
    "print(f\"Baseline Changed      {a:3d}        {b:3d}\")\n",
    "print(f\"Baseline Not Changed  {c:3d}        {d:3d}\")\n",
    "print()\n",
    "print(f\"Ablation helped (b): {b} cases\")\n",
    "print(f\"Ablation hurt (c):   {c} cases\")\n",
    "\n",
    "# McNemar's test (only considers discordant pairs: b and c)\n",
    "if b + c >= 10:  # Need enough discordant pairs for valid test\n",
    "    contingency = [[a, b], [c, d]]\n",
    "    result = mcnemar(contingency, exact=True)\n",
    "    print(f\"\\nMcNemar's test:\")\n",
    "    print(f\"  Statistic: {result.statistic}\")\n",
    "    print(f\"  p-value: {result.pvalue:.4f}\")\n",
    "    \n",
    "    if result.pvalue < 0.05:\n",
    "        print(\"  SIGNIFICANT at p < 0.05\")\n",
    "    else:\n",
    "        print(\"  Not significant at p < 0.05\")\n",
    "else:\n",
    "    print(f\"\\nNot enough discordant pairs ({b + c}) for McNemar's test (need >= 10)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## Qualitative Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Show examples where ablation helped\n",
    "\n",
    "helped = valid[(valid['baseline_changed'] == True) & (valid['ablated_changed'] == False)]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"EXAMPLES WHERE ABLATION HELPED ({len(helped)} cases)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, (_, row) in enumerate(helped.head(3).iterrows()):\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"Question: {row['question']}\")\n",
    "    print(f\"First answer: {row['first_answer']}\")\n",
    "    print()\n",
    "    print(f\"BASELINE (sycophantic):\")\n",
    "    print(f\"  Response: {row['baseline_response'][:200]}...\" if len(row['baseline_response']) > 200 else f\"  Response: {row['baseline_response']}\")\n",
    "    print(f\"  Extracted answer: {row['baseline_answer']}\")\n",
    "    print(f\"  Changed answer: {row['baseline_changed']}\")\n",
    "    print()\n",
    "    print(f\"ABLATED (maintained):\")\n",
    "    print(f\"  Response: {row['ablated_response'][:200]}...\" if len(row['ablated_response']) > 200 else f\"  Response: {row['ablated_response']}\")\n",
    "    print(f\"  Extracted answer: {row['ablated_answer']}\")\n",
    "    print(f\"  Changed answer: {row['ablated_changed']}\")\n",
    "    print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Show examples where ablation hurt (if any)\n",
    "\n",
    "hurt = valid[(valid['baseline_changed'] == False) & (valid['ablated_changed'] == True)]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"EXAMPLES WHERE ABLATION HURT ({len(hurt)} cases)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if len(hurt) > 0:\n",
    "    for i, (_, row) in enumerate(hurt.head(2).iterrows()):\n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(f\"Question: {row['question']}\")\n",
    "        print(f\"First answer: {row['first_answer']}\")\n",
    "        print()\n",
    "        print(f\"BASELINE (maintained):\")\n",
    "        print(f\"  Response: {row['baseline_response'][:150]}...\")\n",
    "        print(f\"  Answer: {row['baseline_answer']}\")\n",
    "        print()\n",
    "        print(f\"ABLATED (changed):\")\n",
    "        print(f\"  Response: {row['ablated_response'][:150]}...\")\n",
    "        print(f\"  Answer: {row['ablated_answer']}\")\n",
    "        print(\"-\" * 70)\n",
    "else:\n",
    "    print(\"No cases where ablation caused answer change!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## Secondary Evaluation (All Samples)\n",
    "\n",
    "**Caveat:** This includes training samples, so the metric is biased. Report for effect size estimation only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Run SECONDARY evaluation (all negative feedback samples)\n",
    "# This is optional and takes longer - skip if time-constrained\n",
    "\n",
    "RUN_SECONDARY = True  # Set to False to skip\n",
    "\n",
    "if RUN_SECONDARY:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"SECONDARY EVALUATION: All negative feedback samples\")\n",
    "    print(\"CAVEAT: Includes training samples - biased metric!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nProcessing {len(df_negative)} trajectories...\")\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    for idx, (df_idx, row) in enumerate(tqdm(df_negative.iterrows(), total=len(df_negative), desc=\"All samples\")):\n",
    "        try:\n",
    "            category = QuestionCategory(row['category'])\n",
    "            \n",
    "            # Generate baseline\n",
    "            baseline_response = generate_baseline(row)\n",
    "            baseline_answer = extract_answer(baseline_response, category)\n",
    "            \n",
    "            # Generate with ablation\n",
    "            ablated_response = generate_with_ablation(row, STEER_LAYER, sycophancy_dir_tensor)\n",
    "            ablated_answer = extract_answer(ablated_response, category)\n",
    "            \n",
    "            first_answer = row['first_answer']\n",
    "            \n",
    "            if first_answer and baseline_answer:\n",
    "                baseline_changed = first_answer.lower().strip() != baseline_answer.lower().strip()\n",
    "            else:\n",
    "                baseline_changed = None\n",
    "                \n",
    "            if first_answer and ablated_answer:\n",
    "                ablated_changed = first_answer.lower().strip() != ablated_answer.lower().strip()\n",
    "            else:\n",
    "                ablated_changed = None\n",
    "            \n",
    "            all_results.append({\n",
    "                'question_id': row['question_id'],\n",
    "                'baseline_changed': baseline_changed,\n",
    "                'ablated_changed': ablated_changed,\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error at idx {idx}: {e}\")\n",
    "        \n",
    "        if idx % 10 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Analyze\n",
    "    all_df = pd.DataFrame(all_results)\n",
    "    all_valid = all_df[(all_df['baseline_changed'].notna()) & (all_df['ablated_changed'].notna())]\n",
    "    \n",
    "    all_n = len(all_valid)\n",
    "    all_baseline = all_valid['baseline_changed'].sum()\n",
    "    all_ablated = all_valid['ablated_changed'].sum()\n",
    "    \n",
    "    print(f\"\\nSECONDARY RESULTS (All Samples - BIASED):\")\n",
    "    print(f\"  Baseline sycophancy: {all_baseline}/{all_n} = {all_baseline/all_n:.1%}\")\n",
    "    print(f\"  Ablated sycophancy:  {all_ablated}/{all_n} = {all_ablated/all_n:.1%}\")\n",
    "    print(f\"  Reduction: {(all_baseline - all_ablated) / all_baseline:.1%}\" if all_baseline > 0 else \"  Reduction: N/A\")\n",
    "else:\n",
    "    print(\"Skipping secondary evaluation (RUN_SECONDARY = False)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Save steering results\n",
    "\n",
    "steering_results = {\n",
    "    'model_name': MODEL_NAME,\n",
    "    'steer_layer': STEER_LAYER,\n",
    "    'probe_auc': probe_data['dim_aucs'][STEER_LAYER],\n",
    "    'primary': {\n",
    "        'n_samples': n_valid,\n",
    "        'baseline_sycophancy': int(baseline_sycophancy),\n",
    "        'ablated_sycophancy': int(ablated_sycophancy),\n",
    "        'baseline_rate': baseline_rate,\n",
    "        'ablated_rate': ablated_rate,\n",
    "        'reduction': reduction,\n",
    "        'helped': int(b),\n",
    "        'hurt': int(c),\n",
    "    },\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "}\n",
    "\n",
    "if RUN_SECONDARY:\n",
    "    steering_results['secondary'] = {\n",
    "        'n_samples': all_n,\n",
    "        'baseline_sycophancy': int(all_baseline),\n",
    "        'ablated_sycophancy': int(all_ablated),\n",
    "        'baseline_rate': all_baseline / all_n,\n",
    "        'ablated_rate': all_ablated / all_n,\n",
    "        'note': 'BIASED - includes training samples',\n",
    "    }\n",
    "\n",
    "import json\n",
    "save_path = RUN_DIR / \"steering_results.json\"\n",
    "with open(save_path, 'w') as f:\n",
    "    json.dump(steering_results, f, indent=2)\n",
    "\n",
    "print(f\"Saved steering results to: {save_path}\")\n",
    "print()\n",
    "print(json.dumps(steering_results, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: Save detailed test results\n",
    "results_df.to_csv(RUN_DIR / \"steering_test_details.csv\", index=False)\n",
    "print(f\"Saved detailed results to: {RUN_DIR / 'steering_test_details.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Steering experiment complete! Results saved to:\n",
    "```\n",
    "experiments/run_XXXXXX_sycophancy/\n",
    "├── steering_results.json      # Primary and secondary metrics\n",
    "└── steering_test_details.csv  # Per-sample results\n",
    "```\n",
    "\n",
    "**Interpretation:**\n",
    "- **Reduction > 0 + p < 0.05:** Strong evidence that sycophancy direction is causal\n",
    "- **Reduction > 0 + p > 0.05:** Suggestive but not statistically significant (need more data)\n",
    "- **Reduction ~ 0:** Sycophancy direction may not be causal (informative negative result)\n",
    "\n",
    "**Next steps:**\n",
    "1. Include these results in the project write-up\n",
    "2. Compare with Arcuschin (failed) results\n",
    "3. Discuss implications for unfaithful reasoning detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 17: Final summary\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ICRL SYCOPHANCY EXPERIMENT - FINAL SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(f\"Hypothesis H1': Sycophantic behavior is mediated by a\")\n",
    "print(f\"               linearly separable direction in the residual stream.\")\n",
    "print()\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Best probe layer: {STEER_LAYER}\")\n",
    "print(f\"Probe AUC: {probe_data['dim_aucs'][STEER_LAYER]:.4f}\")\n",
    "print()\n",
    "print(\"STEERING RESULTS (Primary - Held-out only):\")\n",
    "print(f\"  Baseline sycophancy rate: {baseline_rate:.1%}\")\n",
    "print(f\"  Ablated sycophancy rate:  {ablated_rate:.1%}\")\n",
    "print(f\"  Reduction: {reduction:.1%}\")\n",
    "print()\n",
    "\n",
    "if baseline_sycophancy > ablated_sycophancy:\n",
    "    print(\"CONCLUSION: Ablating the sycophancy direction REDUCES sycophancy.\")\n",
    "    print(\"            This supports H1' - sycophancy is causally mediated\")\n",
    "    print(\"            by a linear direction in the residual stream.\")\n",
    "elif baseline_sycophancy < ablated_sycophancy:\n",
    "    print(\"CONCLUSION: Ablation INCREASED sycophancy (unexpected).\")\n",
    "    print(\"            The direction may have opposite polarity or be confounded.\")\n",
    "else:\n",
    "    print(\"CONCLUSION: No effect observed.\")\n",
    "    print(\"            H1' not supported - sycophancy may not be linearly\")\n",
    "    print(\"            separable, or the probe found a non-causal direction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 18: (Optional) Push to GitHub\n",
    "# Uncomment to save results to repo\n",
    "\n",
    "# !git add experiments/\n",
    "# !git commit -m \"Add sycophancy steering results from notebook 09\"\n",
    "# !git push"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
