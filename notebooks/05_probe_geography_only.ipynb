{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nawidayima/IPHR_Direction/blob/main/notebooks/05_probe_geography_only.ipynb)\n",
    "\n",
    "# Geography-Only Probe (Question B Focus)\n",
    "\n",
    "**Goal:** Train a cleaner probe by focusing on:\n",
    "1. **Geography domain only** - removes cross-domain confounds\n",
    "2. **Question B only** - the \"rationalization\" moment where the model should give the opposite answer\n",
    "\n",
    "**Why Question B?**\n",
    "- Question A: \"Is Paris south of Cairo?\" → Model reasons and answers\n",
    "- Question B: \"Is Cairo south of Paris?\" → Model should give opposite answer\n",
    "- In contradiction cases, the model says NO to both, \"rationalizing\" a wrong answer for B\n",
    "\n",
    "**Evaluation:** 5-fold cross-validation (small sample size requires robust estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 0: Setup - Clone repo and install dependencies\n",
    "# NOTE: After running this cell, RESTART RUNTIME then run from Cell 1\n",
    "\n",
    "import os\n",
    "\n",
    "if not os.path.exists('/content/IPHR_Direction'):\n",
    "    !git clone https://github.com/nawidayima/IPHR_Direction.git\n",
    "    %cd /content/IPHR_Direction\n",
    "else:\n",
    "    %cd /content/IPHR_Direction\n",
    "    !git pull\n",
    "\n",
    "!pip install torch numpy pandas scikit-learn matplotlib -q\n",
    "!pip install -e . -q\n",
    "\n",
    "print(\"Setup complete! Restart runtime and run from Cell 1.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Imports complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Device check\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "print(\"Note: Probe training uses CPU (fast enough for small data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Filter Data\n",
    "\n",
    "We'll load the full activation dataset, then filter to:\n",
    "- Geography domain only\n",
    "- Question B only (where rationalization occurs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Load activations\n",
    "%cd /content/IPHR_Direction\n",
    "\n",
    "RUN_DIR = Path(\"experiments/run_20251228_204835_expand_dataset\")\n",
    "ACTIVATIONS_PATH = RUN_DIR / \"activations/residual_stream_activations.pt\"\n",
    "\n",
    "data = torch.load(ACTIVATIONS_PATH)\n",
    "\n",
    "print(\"Full dataset:\")\n",
    "print(f\"  Total samples: {data['n_samples']}\")\n",
    "print(f\"  Layers: {data['layers']}\")\n",
    "print(f\"  d_model: {data['d_model']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Filter to Geography, Question B only\n",
    "metadata = data['metadata']\n",
    "labels = data['labels'].numpy()\n",
    "\n",
    "# Find indices for geography domain, question B only\n",
    "geo_b_indices = []\n",
    "for i, m in enumerate(metadata):\n",
    "    if m['domain'] == 'geography' and m['question_type'] == 'B':\n",
    "        geo_b_indices.append(i)\n",
    "\n",
    "geo_b_indices = np.array(geo_b_indices)\n",
    "\n",
    "print(f\"Filtered to Geography, Question B:\")\n",
    "print(f\"  Total samples: {len(geo_b_indices)}\")\n",
    "\n",
    "# Get filtered labels\n",
    "filtered_labels = labels[geo_b_indices]\n",
    "n_contradiction = filtered_labels.sum()\n",
    "n_honest = len(filtered_labels) - n_contradiction\n",
    "\n",
    "print(f\"  Contradictions: {n_contradiction}\")\n",
    "print(f\"  Honest: {n_honest}\")\n",
    "print(f\"  Balance: {n_contradiction/len(filtered_labels)*100:.1f}% contradiction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Extract filtered activations per layer\n",
    "filtered_activations = {}\n",
    "for layer in data['layers']:\n",
    "    acts = data['activations'][layer].numpy()\n",
    "    filtered_activations[layer] = acts[geo_b_indices]\n",
    "    print(f\"Layer {layer}: {filtered_activations[layer].shape}\")\n",
    "\n",
    "print(f\"\\nLabels: {filtered_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation Setup\n",
    "\n",
    "With only ~50 samples, a single train/test split would give ~10 test samples - too noisy for reliable AUC estimation.\n",
    "\n",
    "**5-fold cross-validation:**\n",
    "- Split data into 5 equal parts\n",
    "- Train on 4 parts, test on 1 (rotating)\n",
    "- Each sample is tested exactly once\n",
    "- Report: mean AUC ± standard deviation across folds\n",
    "\n",
    "This gives us a more stable estimate of probe performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Set up cross-validation\n",
    "N_FOLDS = 5\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "print(f\"Using {N_FOLDS}-fold stratified cross-validation\")\n",
    "print(f\"Each fold: ~{len(filtered_labels)//N_FOLDS * (N_FOLDS-1)} train, ~{len(filtered_labels)//N_FOLDS} test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference-in-Means with Cross-Validation\n",
    "\n",
    "For each fold:\n",
    "1. Compute DiM direction on training data: `direction = mean(contradiction) - mean(honest)`\n",
    "2. Project test data onto this direction\n",
    "3. Compute ROC-AUC on test data\n",
    "\n",
    "Report mean ± std across all folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Difference-in-Means cross-validation\n",
    "\n",
    "def compute_dim_direction(X, y):\n",
    "    \"\"\"Compute difference-in-means direction.\n",
    "    \n",
    "    Returns unit vector pointing from honest (y=0) toward contradiction (y=1).\n",
    "    \"\"\"\n",
    "    mean_contradiction = X[y == 1].mean(axis=0)\n",
    "    mean_honest = X[y == 0].mean(axis=0)\n",
    "    direction = mean_contradiction - mean_honest\n",
    "    # Normalize to unit vector\n",
    "    direction = direction / np.linalg.norm(direction)\n",
    "    return direction\n",
    "\n",
    "\n",
    "def dim_cross_val(X, y, cv):\n",
    "    \"\"\"Cross-validated ROC-AUC for difference-in-means probe.\"\"\"\n",
    "    aucs = []\n",
    "    for train_idx, test_idx in cv.split(X, y):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Compute direction on training data\n",
    "        direction = compute_dim_direction(X_train, y_train)\n",
    "        \n",
    "        # Score test data\n",
    "        scores = X_test @ direction\n",
    "        \n",
    "        # Compute AUC\n",
    "        auc = roc_auc_score(y_test, scores)\n",
    "        aucs.append(auc)\n",
    "    \n",
    "    return np.array(aucs)\n",
    "\n",
    "\n",
    "# Run for each layer\n",
    "print(\"Difference-in-Means Cross-Validation Results\")\n",
    "print(\"=\" * 50)\n",
    "print()\n",
    "\n",
    "dim_results = {}\n",
    "for layer in data['layers']:\n",
    "    X = filtered_activations[layer]\n",
    "    y = filtered_labels\n",
    "    \n",
    "    aucs = dim_cross_val(X, y, skf)\n",
    "    dim_results[layer] = aucs\n",
    "    \n",
    "    mean_auc = aucs.mean()\n",
    "    std_auc = aucs.std()\n",
    "    \n",
    "    # Interpret\n",
    "    if mean_auc >= 0.8:\n",
    "        status = \"GOOD SIGNAL\"\n",
    "    elif mean_auc >= 0.7:\n",
    "        status = \"WEAK SIGNAL\"\n",
    "    elif mean_auc >= 0.55:\n",
    "        status = \"marginal\"\n",
    "    else:\n",
    "        status = \"no signal\"\n",
    "    \n",
    "    print(f\"Layer {layer}: AUC = {mean_auc:.3f} ± {std_auc:.3f}  [{status}]\")\n",
    "    print(f\"           Fold AUCs: {aucs.round(3)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Visualize DiM results across folds\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "layers = list(dim_results.keys())\n",
    "x_pos = np.arange(len(layers))\n",
    "\n",
    "means = [dim_results[l].mean() for l in layers]\n",
    "stds = [dim_results[l].std() for l in layers]\n",
    "\n",
    "bars = ax.bar(x_pos, means, yerr=stds, capsize=5, color='steelblue', alpha=0.7)\n",
    "ax.axhline(y=0.5, color='red', linestyle='--', label='Random (0.5)')\n",
    "ax.axhline(y=0.7, color='orange', linestyle='--', label='Weak signal (0.7)')\n",
    "ax.axhline(y=0.8, color='green', linestyle='--', label='Good signal (0.8)')\n",
    "\n",
    "ax.set_xlabel('Layer')\n",
    "ax.set_ylabel('ROC-AUC')\n",
    "ax.set_title('Difference-in-Means: Geography Question B Only\\n(5-fold CV, error bars = std)')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels([f'Layer {l}' for l in layers])\n",
    "ax.set_ylim(0, 1)\n",
    "ax.legend(loc='lower right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (m, s) in enumerate(zip(means, stds)):\n",
    "    ax.text(i, m + s + 0.02, f'{m:.3f}', ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with Cross-Validation\n",
    "\n",
    "Logistic regression learns the optimal direction for classification, potentially better than DiM.\n",
    "\n",
    "We try multiple regularization strengths:\n",
    "- **C = 0.01**: Very strong regularization (direction close to DiM)\n",
    "- **C = 0.1**: Strong regularization\n",
    "- **C = 1.0**: Moderate regularization (sklearn default)\n",
    "- **C = 10.0**: Weak regularization (more flexible, risk of overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Logistic Regression cross-validation with multiple C values\n",
    "\n",
    "C_VALUES = [0.01, 0.1, 1.0, 10.0]\n",
    "\n",
    "print(\"Logistic Regression Cross-Validation Results\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "lr_results = {}  # layer -> {C -> aucs}\n",
    "\n",
    "for layer in data['layers']:\n",
    "    X = filtered_activations[layer]\n",
    "    y = filtered_labels\n",
    "    \n",
    "    lr_results[layer] = {}\n",
    "    \n",
    "    print(f\"Layer {layer}:\")\n",
    "    for C in C_VALUES:\n",
    "        lr = LogisticRegression(\n",
    "            C=C,\n",
    "            penalty='l2',\n",
    "            solver='lbfgs',\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # Cross-validation\n",
    "        aucs = cross_val_score(lr, X, y, cv=skf, scoring='roc_auc')\n",
    "        lr_results[layer][C] = aucs\n",
    "        \n",
    "        print(f\"  C={C:5.2f}: AUC = {aucs.mean():.3f} ± {aucs.std():.3f}\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Compare DiM vs best LR for each layer\n",
    "\n",
    "print(\"Comparison: Difference-in-Means vs Best Logistic Regression\")\n",
    "print(\"=\" * 65)\n",
    "print(f\"{'Layer':<10} {'DiM AUC':<15} {'Best LR AUC':<15} {'Best C':<10}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "best_overall = {'layer': None, 'auc': 0, 'method': None}\n",
    "\n",
    "for layer in data['layers']:\n",
    "    dim_auc = dim_results[layer].mean()\n",
    "    \n",
    "    # Find best C for this layer\n",
    "    best_c = None\n",
    "    best_lr_auc = 0\n",
    "    for C in C_VALUES:\n",
    "        auc = lr_results[layer][C].mean()\n",
    "        if auc > best_lr_auc:\n",
    "            best_lr_auc = auc\n",
    "            best_c = C\n",
    "    \n",
    "    print(f\"{layer:<10} {dim_auc:<15.3f} {best_lr_auc:<15.3f} {best_c:<10.2f}\")\n",
    "    \n",
    "    # Track best overall\n",
    "    if dim_auc > best_overall['auc']:\n",
    "        best_overall = {'layer': layer, 'auc': dim_auc, 'method': 'DiM'}\n",
    "    if best_lr_auc > best_overall['auc']:\n",
    "        best_overall = {'layer': layer, 'auc': best_lr_auc, 'method': f'LR(C={best_c})'}\n",
    "\n",
    "print()\n",
    "print(f\"Best overall: Layer {best_overall['layer']}, {best_overall['method']}, AUC = {best_overall['auc']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Visualization\n",
    "\n",
    "Project activations to 2D to visualize class separation.\n",
    "\n",
    "**Caveat:** Overlap in 2D doesn't mean classes are inseparable - the signal might be in dimensions PCA doesn't prioritize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: PCA visualization for best layer\n",
    "\n",
    "best_layer = best_overall['layer']\n",
    "X_best = filtered_activations[best_layer]\n",
    "\n",
    "# Fit PCA\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_2d = pca.fit_transform(X_best)\n",
    "\n",
    "print(f\"PCA on Layer {best_layer}:\")\n",
    "print(f\"  Variance explained: PC1={pca.explained_variance_ratio_[0]*100:.1f}%, PC2={pca.explained_variance_ratio_[1]*100:.1f}%\")\n",
    "print(f\"  Total: {pca.explained_variance_ratio_.sum()*100:.1f}%\")\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "contradiction_mask = filtered_labels == 1\n",
    "honest_mask = filtered_labels == 0\n",
    "\n",
    "ax.scatter(\n",
    "    X_2d[honest_mask, 0], X_2d[honest_mask, 1],\n",
    "    c='blue', alpha=0.7, s=80, label=f'Honest (n={honest_mask.sum()})',\n",
    "    edgecolors='white', linewidth=0.5\n",
    ")\n",
    "ax.scatter(\n",
    "    X_2d[contradiction_mask, 0], X_2d[contradiction_mask, 1],\n",
    "    c='red', alpha=0.7, s=80, label=f'Contradiction (n={contradiction_mask.sum()})',\n",
    "    edgecolors='white', linewidth=0.5\n",
    ")\n",
    "\n",
    "# Add centroids\n",
    "centroid_honest = X_2d[honest_mask].mean(axis=0)\n",
    "centroid_contra = X_2d[contradiction_mask].mean(axis=0)\n",
    "\n",
    "ax.scatter(*centroid_honest, c='blue', s=200, marker='*', edgecolors='black', linewidth=2, zorder=5)\n",
    "ax.scatter(*centroid_contra, c='red', s=200, marker='*', edgecolors='black', linewidth=2, zorder=5)\n",
    "\n",
    "# Draw arrow between centroids\n",
    "ax.annotate('', xy=centroid_contra, xytext=centroid_honest,\n",
    "            arrowprops=dict(arrowstyle='->', color='green', lw=2))\n",
    "\n",
    "ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)')\n",
    "ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)')\n",
    "ax.set_title(f'Geography Question B: Layer {best_layer}\\n(Stars = centroids, Arrow = DiM direction)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Analysis\n",
    "\n",
    "If the signal is still weak, let's analyze the data more carefully:\n",
    "1. Do contradictions cluster by difficulty level?\n",
    "2. Are there specific patterns in which pairs cause contradictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Load geography CSV for detailed analysis\n",
    "\n",
    "geo_df = pd.read_csv(RUN_DIR / \"trajectories/geography.csv\")\n",
    "\n",
    "print(\"Geography data summary:\")\n",
    "print(f\"  Total pairs: {len(geo_df)}\")\n",
    "print()\n",
    "print(\"Contradiction rate by difficulty:\")\n",
    "difficulty_stats = geo_df.groupby('difficulty')['is_contradiction'].agg(['sum', 'count', 'mean'])\n",
    "difficulty_stats.columns = ['n_contradiction', 'n_total', 'rate']\n",
    "print(difficulty_stats.to_string())\n",
    "print()\n",
    "\n",
    "# Show which pairs caused contradictions\n",
    "print(\"Contradiction cases:\")\n",
    "contradictions = geo_df[geo_df['is_contradiction'] == True][['pair_id', 'entity_x', 'entity_y', 'difficulty', 'answer_a', 'answer_b']]\n",
    "print(contradictions.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Analyze patterns in contradictions\n",
    "\n",
    "# Most contradictions should be NO/NO (model says both are \"not south of\" each other)\n",
    "answer_patterns = geo_df.groupby(['answer_a', 'answer_b', 'is_contradiction']).size().reset_index(name='count')\n",
    "print(\"Answer patterns:\")\n",
    "print(answer_patterns.to_string())\n",
    "print()\n",
    "\n",
    "# Check if contradictions are systematically wrong\n",
    "print(\"\\nFor contradiction cases:\")\n",
    "contra_df = geo_df[geo_df['is_contradiction'] == True]\n",
    "print(f\"  Answer A distribution: {contra_df['answer_a'].value_counts().to_dict()}\")\n",
    "print(f\"  Answer B distribution: {contra_df['answer_b'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Save results\n",
    "\n",
    "results_dir = RUN_DIR / \"probes\"\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Compile results\n",
    "save_data = {\n",
    "    'experiment': 'geography_question_b_only',\n",
    "    'n_samples': len(filtered_labels),\n",
    "    'n_contradiction': int(filtered_labels.sum()),\n",
    "    'n_honest': int((1 - filtered_labels).sum()),\n",
    "    'n_folds': N_FOLDS,\n",
    "    'layers': data['layers'],\n",
    "    \n",
    "    # DiM results\n",
    "    'dim_results': {layer: {\n",
    "        'aucs': dim_results[layer].tolist(),\n",
    "        'mean': float(dim_results[layer].mean()),\n",
    "        'std': float(dim_results[layer].std())\n",
    "    } for layer in data['layers']},\n",
    "    \n",
    "    # LR results\n",
    "    'lr_results': {layer: {\n",
    "        str(C): {\n",
    "            'aucs': lr_results[layer][C].tolist(),\n",
    "            'mean': float(lr_results[layer][C].mean()),\n",
    "            'std': float(lr_results[layer][C].std())\n",
    "        } for C in C_VALUES\n",
    "    } for layer in data['layers']},\n",
    "    \n",
    "    'best_overall': best_overall,\n",
    "}\n",
    "\n",
    "save_path = results_dir / \"geography_question_b_results.pt\"\n",
    "torch.save(save_data, save_path)\n",
    "print(f\"Results saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook tested probes on a cleaner dataset:\n",
    "- Geography domain only (no cross-domain confounds)\n",
    "- Question B only (the \"rationalization\" moment)\n",
    "- 5-fold cross-validation for robust estimation\n",
    "\n",
    "**Key results:**\n",
    "- Best layer and method shown above\n",
    "- If AUC still ~0.5: The rationalization signal may not be linearly separable in residual stream\n",
    "- If AUC improved: Focusing on the right subset of data helped\n",
    "\n",
    "**If signal is still weak, possible next steps:**\n",
    "1. Try different token positions (e.g., first generated token instead of last prompt token)\n",
    "2. Look at attention patterns instead of residual stream\n",
    "3. Try non-linear probes\n",
    "4. Increase dataset size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
